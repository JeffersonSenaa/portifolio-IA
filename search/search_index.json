{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Portf\u00f3lio de Intelig\u00eancia Artificial","text":"<p>Este reposit\u00f3rio apresenta os portf\u00f3lios desenvolvidos durante a disciplina de Intelig\u00eancia Artificial, no curso de Engenharia de Software da Universidade de Bras\u00edlia.</p> <p>Baseado nos princ\u00edpios pedag\u00f3gicos de Benigna Maria de Freitas Villas Boas (2008), este portf\u00f3lio \u00e9 uma cole\u00e7\u00e3o comentada e reflexiva de conte\u00fados, conceitos, algoritmos e an\u00e1lises voltados \u00e0 Intelig\u00eancia Artificial, elaboradas ao longo da disciplina. \u00c9 mais do que uma simples reuni\u00e3o de conte\u00fados, o portf\u00f3lio \u00e9 uma ferramenta de aprendizagem ativa, autoavalia\u00e7\u00e3o e demonstra\u00e7\u00e3o de compet\u00eancias.</p> <ul> <li> <p> Portf\u00f3lio 2</p> <p>Explora\u00e7\u00e3o de algoritmos de busca cega e informada, incluindo implementa\u00e7\u00f5es pr\u00e1ticas e an\u00e1lises de desempenho.</p> <p> Acessar</p> </li> <li> <p> Portf\u00f3lio 3</p> <p>Implementa\u00e7\u00e3o e an\u00e1lise de Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (CSPs) com exemplos pr\u00e1ticos e otimiza\u00e7\u00f5es.</p> <p> Acessar</p> </li> </ul>"},{"location":"#objetivos-do-portfolio","title":"Objetivos do Portf\u00f3lio","text":"<ul> <li>Demonstrar habilidades, compet\u00eancias e valores aprendidos ao longo dos estudos da disciplina;</li> <li>Refletir sobre os conte\u00fados trabalhados em sala de aula e fora dela;</li> <li>Explicar conceitos com autoria pr\u00f3pria, a partir das aulas, pesquisas e estudos individuais;</li> <li>Servir como instrumento de avalia\u00e7\u00e3o formativa pelo professor;</li> <li>Organizar produ\u00e7\u00f5es autorais, como textos, c\u00f3digos e projetos, com an\u00e1lise cr\u00edtica e contextualiza\u00e7\u00e3o.</li> </ul>"},{"location":"#estrutura-dos-topicos","title":"Estrutura dos T\u00f3picos","text":"<p>Os temas do portif\u00f3lio foram estruturados segundo os seguintes elementos:</p> <ol> <li>Introdu\u00e7\u00e3o ao Conte\u00fado </li> <li>Apresenta\u00e7\u00e3o da import\u00e2ncia do tema no contexto socioecon\u00f4mico, pol\u00edtico e tecnol\u00f3gico.</li> <li>Explora\u00e7\u00e3o e An\u00e1lise Cr\u00edtica </li> <li>Organiza\u00e7\u00e3o dos conceitos, com materiais pesquisados, referenciados e comentados.</li> <li>Problemas, Projetos e Aplica\u00e7\u00f5es </li> <li>Proposi\u00e7\u00e3o de exerc\u00edcios, problemas ou projetos autorais com solu\u00e7\u00f5es desenvolvidas e comentadas.</li> <li>Conclus\u00e3o </li> <li>Reflex\u00e3o sobre vantagens, limita\u00e7\u00f5es e principais aprendizados do t\u00f3pico.</li> </ol>"},{"location":"#capitulos-do-portifolio","title":"Cap\u00edtulos do Portif\u00f3lio","text":"<ol> <li>Introdu\u00e7\u00e3o \u00e0 Intelig\u00eancia Artificial</li> <li>Hist\u00f3rico, estado da arte, benef\u00edcios, riscos, agentes inteligentes, ambientes e racionalidade.</li> <li>Resolu\u00e7\u00e3o de Problemas por Busca</li> <li>Busca cega, informada e em ambientes complexos com algoritmos implementados em Python.</li> <li>Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es</li> <li>Modelagem e resolu\u00e7\u00e3o de CSPs (Constraint Satisfaction Problems).</li> <li>Agentes L\u00f3gicos</li> <li>Representa\u00e7\u00e3o do conhecimento e infer\u00eancia por meio da l\u00f3gica proposicional e de predicados.</li> <li>Incerteza e Redes Bayesianas</li> <li>Probabilidade, infer\u00eancia bayesiana, filtros de Kalman e racioc\u00ednio probabil\u00edstico ao longo do tempo.</li> <li>Aprendizado de M\u00e1quina</li> <li>Fundamentos do aprendizado supervisionado, n\u00e3o supervisionado e suas aplica\u00e7\u00f5es pr\u00e1ticas.</li> </ol>"},{"location":"#tecnologias-e-ferramentas-utilizadas","title":"Tecnologias e Ferramentas Utilizadas","text":"<ul> <li>Python \u2013 Implementa\u00e7\u00e3o dos algoritmos</li> <li>MkDocs \u2013 Estrutura e navega\u00e7\u00e3o do portf\u00f3lio</li> <li>MkDocs Material \u2013 Tema visual moderno</li> </ul>"},{"location":"#formato-de-apresentacao","title":"Formato de Apresenta\u00e7\u00e3o","text":"<p>Este portf\u00f3lio utiliza o formato de relat\u00f3rio estruturado com navega\u00e7\u00e3o digital, utilizando o MkDocs. Outras formas, como fichamento, mapa mental ou v\u00eddeo, poder\u00e3o ser adicionadas conforme a necessidade.</p> <p>Todos os materiais s\u00e3o referenciados e comentados, em conformidade com os crit\u00e9rios de avalia\u00e7\u00e3o da disciplina.</p>"},{"location":"#autor-jefferson-sena","title":"Autor: Jefferson Sena","text":"<ul> <li> GitHub</li> <li> LinkedIn</li> </ul> <p>Estudante de Engenharia de Software - Universidade de Bras\u00edlia (UnB) Reposit\u00f3rio acad\u00eamico desenvolvido para a disciplina de Intelig\u00eancia Artificial  </p>"},{"location":"#licenca","title":"Licen\u00e7a","text":"<p>Este material \u00e9 disponibilizado sob a Licen\u00e7a MIT. Uso educacional incentivado.</p> <p>\u201cO portf\u00f3lio \u00e9 um instrumento de avalia\u00e7\u00e3o e reflex\u00e3o que permite que o estudante se reconhe\u00e7a em sua pr\u00f3pria trajet\u00f3ria de aprendizagem.\u201d \u2014 Benigna Maria de Freitas Villas Boas (2008)</p> <p> </p>"},{"location":"portifolio-2/","title":"Portifolio 2","text":""},{"location":"portifolio-2/#algoritmo-de-busca-cega","title":"Algoritmo de busca cega;","text":""},{"location":"portifolio-2/#random-search","title":"Random Search","text":"Python<pre><code>import random\ndef random_search(goal, domain):\nattempts = 0\nwhile True:\nguess = random.choice(domain)\nattempts += 1\nif guess == goal:\nreturn guess, attempts\n</code></pre>"},{"location":"portifolio-2/#o-que-sao-algoritmos-de-busca-cega","title":"O que s\u00e3o Algoritmos de Busca Cega?","text":"<p>Algoritmos de busca cega (ou busca n\u00e3o informada) s\u00e3o algoritmos que n\u00e3o utilizam nenhuma informa\u00e7\u00e3o adicional sobre o problema, como dist\u00e2ncia ou estimativas at\u00e9 o objetivo. Eles exploram o espa\u00e7o de busca de forma sistem\u00e1tica e completa, sem levar em considera\u00e7\u00e3o a posi\u00e7\u00e3o da meta, sendo ent\u00e3o \u201ccegos\u201d quanto ao melhor caminho.</p>"},{"location":"portifolio-2/#origem","title":"Origem","text":"<ul> <li>Surgiram nos anos 1950-60, envolto aos primeiros trabalhos em Intelig\u00eancia Artificial simb\u00f3lica.</li> <li>Aplicados em resolu\u00e7\u00e3o autom\u00e1tica de problemas, como quebra-cabe\u00e7as, jogos simples e sistemas de infer\u00eancia l\u00f3gica.</li> <li>S\u00e3o os primeiros tipos de algoritmos de busca utilizados em IA, tendo ra\u00edzes na teoria de grafos e na teoria dos aut\u00f4matos.</li> </ul>"},{"location":"portifolio-2/#como-funcionam","title":"Como Funcionam?","text":"<p>Eles expandem os n\u00f3s do espa\u00e7o de estados de acordo com uma regra fixa, como:</p> <ul> <li>Em ordem de chegada (fila \u2013 busca em largura).</li> <li>Em ordem de profundidade (pilha \u2013 busca em profundidade).</li> <li>Com menor custo acumulado (busca de custo uniforme).</li> </ul> <p>Esses algoritmos, n\u00e3o sabem se est\u00e3o se aproximando da meta. Apenas tentam todos os caminhos poss\u00edveis dentro do contexto.</p>"},{"location":"portifolio-2/#contextos-de-aplicacao","title":"Contextos de Aplica\u00e7\u00e3o","text":"<p>Embora menos eficientes que os algoritmos informados, os algoritmos de busca cega ainda s\u00e3o \u00fateis quando:</p> <ul> <li>N\u00e3o h\u00e1 informa\u00e7\u00e3o heur\u00edstica confi\u00e1vel dispon\u00edvel.</li> <li>O espa\u00e7o de busca \u00e9 pequeno.</li> <li>\u00c9 necess\u00e1rio garantir que a solu\u00e7\u00e3o seja \u00f3tima ou completa, mesmo sem pistas.</li> </ul> <p>Exemplos de aplica\u00e7\u00f5es:</p> <ul> <li>Solu\u00e7\u00f5es para problemas cl\u00e1ssicos de IA como o problema das torres de Han\u00f3i, quebra-cabe\u00e7as 8-puzzle.</li> <li>Sistemas educacionais, para ensinar l\u00f3gica de busca.</li> <li>Diagn\u00f3stico automatizado onde a heur\u00edstica n\u00e3o \u00e9 clara.</li> <li>Planejamento de a\u00e7\u00f5es simples em jogos e agentes aut\u00f4nomos.</li> </ul>"},{"location":"portifolio-2/#importancia","title":"Import\u00e2ncia","text":"<ul> <li>S\u00e3o a base conceitual para algoritmos mais avan\u00e7ados.</li> <li>Garantem completude (encontram a solu\u00e7\u00e3o, se houver uma).</li> <li>Podem ser usados em qualquer tipo de problema, mesmo sem conhecimento do dom\u00ednio.</li> <li>S\u00e3o \u00fateis para compara\u00e7\u00e3o e benchmarking de novos algoritmos.</li> </ul>"},{"location":"portifolio-2/#1-busca-exaustiva-brute-force-search","title":"1. Busca Exaustiva (Brute-force Search)","text":"<ul> <li>Verifica todas as combina\u00e7\u00f5es poss\u00edveis at\u00e9 encontrar a solu\u00e7\u00e3o.</li> <li>Muito lento, mas simples e confi\u00e1vel.</li> <li>Usado quando o espa\u00e7o de busca \u00e9 pequeno ou para validar solu\u00e7\u00f5es.</li> </ul> Text Only<pre><code>def brute_force_search(problem):\n    for solution in problem.all_possible_solutions():\n        if problem.is_goal(solution):\n            return solution\n    return None\n#Aplicacao: Tentar todas as senhas poss\u00edveis de um cadeado.\n</code></pre>"},{"location":"portifolio-2/#2-backtracking","title":"2. Backtracking","text":"<ul> <li>T\u00e9cnica de busca recursiva que volta atr\u00e1s quando encontra um beco sem sa\u00edda.</li> <li>Muito usada em problemas de combina\u00e7\u00e3o e permuta\u00e7\u00e3o, como Sudoku e quebra-cabe\u00e7as.</li> </ul> Python<pre><code>def solve(problem, state):\n    if problem.is_goal(state):\n        return state\n    for move in problem.legal_moves(state):\n        next_state = problem.apply_move(state, move)\n        result = solve(problem, next_state)\n        if result:\n            return result\n    return None\n#Aplicacao: Resolver o Sudoku ou labirintos.\n</code></pre>"},{"location":"portifolio-2/#3-iterative-deepening-search-ids","title":"3. Iterative Deepening Search (IDS)","text":"<ul> <li>Combina\u00e7\u00e3o de profundidade com garantia de completude.</li> <li>Executa v\u00e1rias buscas em profundidade com profundidade limitada que vai aumentando.</li> <li>Usa pouca mem\u00f3ria encontrando solu\u00e7\u00f5es \u00f3timas.</li> </ul>"},{"location":"portifolio-2/#aplicacao-sudoku-com-backtracking","title":"Aplica\u00e7\u00e3o: Sudoku com Backtracking","text":"<p>Imagine que voc\u00ea est\u00e1 resolvendo um Sudoku. Voc\u00ea n\u00e3o sabe qual n\u00famero colocar, ent\u00e3o tenta todos de 1 a 9 em uma c\u00e9lula vazia. Caso d\u00ea erro, voc\u00ea volta atr\u00e1s e tenta outro n\u00famero \u2014 esse \u00e9 o comportamento t\u00edpico da busca cega com backtracking.</p>"},{"location":"portifolio-2/#algoritmo-de-busca-informada","title":"Algoritmo de busca informada;","text":""},{"location":"portifolio-2/#algoritmo-de-simulated-annealing","title":"Algoritmo de Simulated Annealing","text":"Python<pre><code>import math\nimport random\n\ndef simulated_annealing(objective_function, domain, temp_initial, cooling_rate):\n    current = random.uniform(*domain)\n    temp = temp_initial\n\n    while temp &gt; 1:\n        neighbor = current + random.uniform(-1, 1)\n        neighbor = max(min(neighbor, domain[1]), domain[0])\n        cost_diff = objective_function(neighbor) - objective_function(current)\n\n        if cost_diff &lt; 0 or math.exp(-cost_diff / temp) &gt; random.random():\n            current = neighbor\n\n        temp *= cooling_rate\n\n    return current\n\n# Exemplo: minimizar a fun\u00e7\u00e3o f(x) = x^2\nresult = simulated_annealing(lambda x: x**2, domain=(-10, 10), temp_initial=100, cooling_rate=0.95)\nprint(f\"Solu\u00e7\u00e3o encontrada: {result}, f(x) = {result**2}\")\n#**Aplica\u00e7\u00e3o:** Otimizar de forma cont\u00ednua as fun\u00e7\u00f5es complexas com m\u00ednimos locais.\n</code></pre>"},{"location":"portifolio-2/#o-que-sao-algoritmos-de-busca-informada","title":"O que s\u00e3o Algoritmos de Busca Informada?","text":"<p>Algoritmos de busca informada, s\u00e3o algoritmos que utilizam informa\u00e7\u00f5es adicionais (heur\u00edsticas) sobre o problema para a tomada de decis\u00f5es mais inteligentes durante a busca por solu\u00e7\u00f5es. Tendem a ser mais eficientes do que algoritmos de busca cega (como BFS ou DFS) porque conseguem priorizar caminhos promissores e assim evitar explorar caminhos irrelevantes.</p>"},{"location":"portifolio-2/#origem_1","title":"Origem","text":"<ul> <li>Deriva\u00e7\u00f5es de pesquisas em ci\u00eancia da computa\u00e7\u00e3o e IA cl\u00e1ssica nas d\u00e9cadas de 1960 e 1970.</li> <li>Fortemente influenciados pelo trabalho de nomes como Alan Turing, John McCarthy e Marvin Minsky.</li> <li>Cresceram com os primeiros sistemas de planejamento autom\u00e1tico e resolu\u00e7\u00e3o de problemas em ambientes como jogos e sistemas especialistas.</li> </ul>"},{"location":"portifolio-2/#como-funcionam_1","title":"Como Funcionam?","text":"<p>Esses algoritmos usam uma fun\u00e7\u00e3o heur\u00edstica <code>h(n)</code> que estima o custo restante de um estado <code>n</code> at\u00e9 a solu\u00e7\u00e3o. Essa fun\u00e7\u00e3o:</p> <ul> <li>N\u00e3o precisa ser perfeita, apenas uma boa estimativa.</li> <li>Ajuda a escolher qual n\u00f3 explorar primeiro com base em qual parece mais promissor.</li> </ul>"},{"location":"portifolio-2/#contextos-de-aplicacao_1","title":"Contextos de Aplica\u00e7\u00e3o","text":"<ul> <li>Jogos de estrat\u00e9gia e tabuleiro (ex.: xadrez, damas, sudoku)</li> <li>Planejamento de rotas (ex.: GPS, log\u00edstica)</li> <li>Rob\u00f3tica (ex.: navega\u00e7\u00e3o de rob\u00f4s aut\u00f4nomos)</li> <li>Diagn\u00f3stico autom\u00e1tico e sistemas especialistas</li> <li>Solu\u00e7\u00f5es em tempo real para IA em videogames</li> <li>Assistentes de voz e NLP (em fases de planejamento de di\u00e1logo)</li> </ul>"},{"location":"portifolio-2/#importancia_1","title":"Import\u00e2ncia","text":"<ul> <li>Efici\u00eancia: Exploram menos n\u00f3s que as buscas cegas.</li> <li>Escalabilidade: Lidam melhor com espa\u00e7os de busca grandes.</li> <li>Adaptabilidade: A heur\u00edstica pode ser ajustada para diferentes dom\u00ednios.</li> <li>S\u00e3o a base para algoritmos como A, IDA, Beam Search e etc.</li> </ul>"},{"location":"portifolio-2/#exemplos-de-algoritmos-de-busca-informada","title":"Exemplos de Algoritmos de Busca Informada","text":""},{"location":"portifolio-2/#1-beam-search","title":"1. Beam Search","text":"<ul> <li>Explora apenas os <code>k</code> melhores caminhos em cada n\u00edvel da \u00e1rvore de busca, limitando o n\u00famero de n\u00f3s expandidos.</li> <li>Usado em NLP (ex: tradu\u00e7\u00e3o autom\u00e1tica), pois \u00e9 mais eficiente do que expandir todos os caminhos poss\u00edveis.</li> </ul> Python<pre><code>import heapq\n\ndef beam_search(start, goal, neighbors, heuristic, beam_width):\n    beam = [(heuristic(start, goal), start)]\n    while beam:\n        new_beam = []\n        for _, node in beam:\n            if node == goal:\n                return node\n            for neighbor in neighbors(node):\n                cost = heuristic(neighbor, goal)\n                heapq.heappush(new_beam, (cost, neighbor))\n        beam = heapq.nsmallest(beam_width, new_beam)\n    return None\n</code></pre>"},{"location":"portifolio-2/#2-iterative-deepening-a-ida","title":"2. Iterative Deepening A (IDA)","text":"<ul> <li>Combina a busca em profundidade com heur\u00edsticas.</li> <li>Utiliza limites crescentes baseados na fun\u00e7\u00e3o <code>f(n) = g(n) + h(n)</code>.</li> </ul>"},{"location":"portifolio-2/#3-weighted-a","title":"3. Weighted A*","text":"<ul> <li>Variante do A*, mas multiplica a heur\u00edstica por um fator <code>w</code>:<ul> <li><code>f(n) = g(n) + w * h(n)</code></li> </ul> </li> <li>Com <code>w &gt; 1</code>, torna-se mais r\u00e1pido, mas menos preciso.</li> <li>Usado quando o tempo \u00e9 mais importante que a perfei\u00e7\u00e3o (ex: jogos ou rob\u00f4s em tempo real).</li> </ul>"},{"location":"portifolio-2/#exemplo-de-aplicacao-planejamento-de-rota-com-beam-search","title":"Exemplo de Aplica\u00e7\u00e3o: Planejamento de Rota com Beam Search","text":"<p>Imagine um rob\u00f4 de limpeza que decida o caminho mais eficiente at\u00e9 um ponto para recarregar. O mapa da casa \u00e9 representado como um grafo. O algoritmo usa a dist\u00e2ncia euclidiana como heur\u00edstica decidindo quais caminhos explorar primeiro, evitando paredes e obst\u00e1culos.</p>"},{"location":"portifolio-2/#algoritmo-de-busca-em-ambientes-complexos-gradient-descent-ou-hill-climbing","title":"Algoritmo de busca em ambientes complexos (Gradient Descent ou Hill Climbing)","text":""},{"location":"portifolio-2/#ambiente-complexo-algoritmo-de-gradiente-descendente","title":"Ambiente Complexo \u2014 Algoritmo de Gradiente Descendente","text":"Python<pre><code>def gradient_descent(derivative_func, start, learning_rate, n_iterations):\n    x = start\n    for _ in range(n_iterations):\n        grad = derivative_func(x)\n        x = x - learning_rate * grad\n    return x\n\n# Exemplo: minimizar f(x) = x^2 \u2192 f'(x) = 2x\nminimum = gradient_descent(lambda x: 2*x, start=10.0, learning_rate=0.1, n_iterations=100)\nprint(f\"M\u00ednimo encontrado: x = {minimum}, f(x) = {minimum**2}\")\n</code></pre>"},{"location":"portifolio-2/#o-que-sao-algoritmos-de-busca-em-ambientes-complexos","title":"O que s\u00e3o Algoritmos de Busca em Ambientes Complexos?","text":"<p>S\u00e3o algoritmos usados quando o espa\u00e7o de busca \u00e9 muito grande, cont\u00ednuo ou din\u00e2mico, o que torna invi\u00e1vel testar todas as solu\u00e7\u00f5es poss\u00edveis. Eles buscam melhorar uma solu\u00e7\u00e3o progressivamente, explorando os arredores de uma solu\u00e7\u00e3o atual com base em algum crit\u00e9rio de melhoria.</p>"},{"location":"portifolio-2/#principais-tipos","title":"Principais Tipos","text":""},{"location":"portifolio-2/#1-gradient-descent-descida-do-gradiente","title":"1. Gradient Descent (Descida do Gradiente)","text":"<ul> <li>Tipo: Algoritmo de otimiza\u00e7\u00e3o cont\u00ednua.</li> <li>Utiliza\u00e7\u00e3o: A fun\u00e7\u00e3o objetivo \u00e9 diferenci\u00e1vel (ou seja, podemos calcular sua derivada).</li> <li>Ideia: Dado um ponto inicial, move-se na dire\u00e7\u00e3o do gradiente negativo da fun\u00e7\u00e3o, que \u00e9 a dire\u00e7\u00e3o de maior \"decl\u00ednio\" da fun\u00e7\u00e3o.</li> </ul>"},{"location":"portifolio-2/#como-funciona","title":"Como funciona:","text":"<ol> <li>Escolhe-se uma solu\u00e7\u00e3o inicial (ex: peso de um modelo).</li> <li>Calcula-se o gradiente (a inclina\u00e7\u00e3o) da fun\u00e7\u00e3o no ponto atual.</li> <li>Move-se na dire\u00e7\u00e3o oposta ao gradiente.</li> <li>Repete-se o processo at\u00e9 atingir um m\u00ednimo local ou global.</li> </ol>"},{"location":"portifolio-2/#formula-basica-x-x-fx","title":"F\u00f3rmula b\u00e1sica:   x = x - \u03b1 * \u2207f(x)","text":""},{"location":"portifolio-2/#2-busca-local-hill-climbing-simulated-annealing-etc","title":"2. Busca Local (Hill Climbing, Simulated Annealing, etc.)","text":"<ul> <li>Tipo: Heur\u00edsticas de otimiza\u00e7\u00e3o baseadas em melhorar uma solu\u00e7\u00e3o atual.</li> <li>Diferente do Gradient Descent: N\u00e3o depende de derivadas, funciona com fun\u00e7\u00f5es n\u00e3o cont\u00ednuas.</li> <li>Exemplo relevante: Simulated Annealing, que permite aceitar piores solu\u00e7\u00f5es com alguma probabilidade para escapar de m\u00ednimos locais.</li> </ul>"},{"location":"portifolio-2/#origem-e-contexto-historico","title":"Origem e Contexto Hist\u00f3rico","text":"<ul> <li>O Gradient Descent surgiu no contexto do c\u00e1lculo multivariado e foi adaptado para problemas de IA a partir da d\u00e9cada de 1950.</li> <li>Tornou-se extremamente popular na aprendizagem de m\u00e1quina com o surgimento das redes neurais.</li> <li>M\u00e9todos de busca local t\u00eam origem em t\u00e9cnicas de otimiza\u00e7\u00e3o cl\u00e1ssica, mas evolu\u00edram para lidar com problemas n\u00e3o determin\u00edsticos e estoc\u00e1sticos em IA.</li> </ul>"},{"location":"portifolio-2/#aplicacoes-na-inteligencia-artificial","title":"Aplica\u00e7\u00f5es na Intelig\u00eancia Artificial","text":""},{"location":"portifolio-2/#gradient-descent","title":"Gradient Descent:","text":"<ul> <li>Aprendizado de m\u00e1quina: Treinamento de redes neurais profundas, regress\u00e3o log\u00edstica, SVM, etc.</li> <li>Redu\u00e7\u00e3o de erro: Minimiza uma fun\u00e7\u00e3o de custo, como erro quadr\u00e1tico m\u00e9dio (MSE).</li> <li>Modelos probabil\u00edsticos: Ajuste de par\u00e2metros em modelos como Naive Bayes ou HMM.</li> </ul>"},{"location":"portifolio-2/#outros-algoritmos-de-busca-local","title":"Outros algoritmos de busca local:","text":"<ul> <li>Otimiza\u00e7\u00e3o de hiperpar\u00e2metros (ex: n\u00famero de neur\u00f4nios, taxa de aprendizado).</li> <li>Planejamento de a\u00e7\u00f5es em IA (com Simulated Annealing ou algoritmos estoc\u00e1sticos).</li> <li>IA em jogos e rob\u00f3tica, onde o ambiente muda e n\u00e3o h\u00e1 tempo para uma busca exaustiva.</li> </ul>"},{"location":"portifolio-2/#exemplos-de-algoritmos","title":"Exemplos de Algoritmos","text":""},{"location":"portifolio-2/#1-gradient-descent","title":"1. Gradient Descent","text":"Python<pre><code># Minimizar a fun\u00e7\u00e3o f(x) = (x - 5)**2\ndef f(x):\n    return (x - 5)**2\n\ndef grad_f(x):\n    return 2 * (x - 5)\n\nx = 0  # ponto inicial\nlr = 0.1  # taxa de aprendizado\n\nfor _ in range(100):\n    x -= lr * grad_f(x)\n\nprint(f\"M\u00ednimo encontrado em x = {x}\")\n#Converge para x = 5, que \u00e9 o m\u00ednimo global da fun\u00e7\u00e3o.\n</code></pre>"},{"location":"portifolio-2/#2-simulated-annealing-busca-local-com-perturbacoes","title":"2. Simulated Annealing (busca local com perturba\u00e7\u00f5es)","text":"Python<pre><code>import math\nimport random\n\ndef objective(x):\n    return (x - 3)**2 + 2\n\nx = random.uniform(-10, 10)\nT = 1.0\nT_min = 0.0001\nalpha = 0.9\n\nwhile T &gt; T_min:\n    new_x = x + random.uniform(-1, 1)\n    delta = objective(new_x) - objective(x)\n    if delta &lt; 0 or random.random() &lt; math.exp(-delta / T):\n        x = new_x\n    T *= alpha\n\nprint(f\"Melhor solu\u00e7\u00e3o encontrada: x = {x}\")\n</code></pre>"},{"location":"portifolio-2/#importancia-dos-algoritmos-em-ambientes-complexos","title":"Import\u00e2ncia dos Algoritmos em Ambientes Complexos","text":"<ul> <li>S\u00e3o fundamentais para resolver problemas onde:<ul> <li>O espa\u00e7o de busca \u00e9 enorme ou cont\u00ednuo.</li> <li>A solu\u00e7\u00e3o exata n\u00e3o \u00e9 conhecida.</li> <li>\u00c9 necess\u00e1rio tempo real ou adapta\u00e7\u00e3o constante (ex: IA em jogos, carros aut\u00f4nomos).</li> </ul> </li> <li>Est\u00e3o na base de muitos avan\u00e7os modernos em deep learning e intelig\u00eancia artificial.</li> </ul> Conceito Gradient Descent Busca Local Precisa de derivada? Sim N\u00e3o Tipo de fun\u00e7\u00e3o Cont\u00ednua Arbitr\u00e1ria Exemplo Treinamento de rede neural Planejamento em IA Vantagem Converg\u00eancia r\u00e1pida Vers\u00e1til para ambientes estoc\u00e1sticos"},{"location":"portifolio-2/#algoritmo-genetico","title":"Algoritmo gen\u00e9tico","text":"Python<pre><code>import random\n\ndef fitness(x):\n    return -1 * (x - 3)**2 + 9  # M\u00e1ximo em x = 3\n\ndef genetic_algorithm(population, generations, mutation_rate=0.1):\n    for _ in range(generations):\n        population.sort(key=fitness, reverse=True)\n        next_gen = population[:2]  # elitismo\n\n        while len(next_gen) &lt; len(population):\n            p1, p2 = random.sample(population[:4], 2)\n            child = (p1 + p2) / 2\n            if random.random() &lt; mutation_rate:\n                child += random.uniform(-1, 1)\n            next_gen.append(child)\n\n        population = next_gen\n\n    best = max(population, key=fitness)\n    return best\n\n# Exemplo: encontrar o m\u00e1ximo da fun\u00e7\u00e3o - (x-3)^2 + 9\ninitial_pop = [random.uniform(0, 6) for _ in range(6)]\nsolution = genetic_algorithm(initial_pop, generations=20)\nprint(f\"Solu\u00e7\u00e3o gen\u00e9tica: x = {solution}, f(x) = {fitness(solution)}\")\n</code></pre>"},{"location":"portifolio-2/#o-que-sao-algoritmos-geneticos","title":"O que s\u00e3o Algoritmos Gen\u00e9ticos?","text":"<p>Algoritmos Gen\u00e9ticos (AGs) s\u00e3o t\u00e9cnicas de otimiza\u00e7\u00e3o e busca inspiradas nos processos de sele\u00e7\u00e3o natural e evolu\u00e7\u00e3o biol\u00f3gica descritos por Charles Darwin. Eles pertencem \u00e0 categoria de algoritmos evolutivos, que usam conceitos como popula\u00e7\u00e3o, muta\u00e7\u00e3o, reprodu\u00e7\u00e3o e sele\u00e7\u00e3o para resolver problemas complexos.</p>"},{"location":"portifolio-2/#origem-dos-algoritmos-geneticos","title":"Origem dos Algoritmos Gen\u00e9ticos","text":"<ul> <li>Foram propostos por John Holland na d\u00e9cada de 1970, na Universidade de Michigan.</li> <li>Holland criou uma estrutura matem\u00e1tica para entender os mecanismos da evolu\u00e7\u00e3o natural e adapt\u00e1-los \u00e0 resolu\u00e7\u00e3o de problemas computacionais.</li> <li>Seu livro de 1975, \"Adaptation in Natural and Artificial Systems\", \u00e9 a base te\u00f3rica dos AGs.</li> </ul>"},{"location":"portifolio-2/#como-funcionam-os-algoritmos-geneticos","title":"Como Funcionam os Algoritmos Gen\u00e9ticos?","text":"<ol> <li>Inicializa\u00e7\u00e3o: Uma popula\u00e7\u00e3o inicial de solu\u00e7\u00f5es (chamadas de indiv\u00edduos ou cromossomos) \u00e9 gerada aleatoriamente.</li> <li>Avalia\u00e7\u00e3o (Fitness): Cada indiv\u00edduo \u00e9 avaliado por uma fun\u00e7\u00e3o de aptid\u00e3o (fitness function) que mede qu\u00e3o boa \u00e9 a solu\u00e7\u00e3o.</li> <li>Sele\u00e7\u00e3o: Indiv\u00edduos mais aptos t\u00eam mais chances de serem escolhidos para gerar descendentes.</li> <li>Crossover (Recombina\u00e7\u00e3o): Partes dos cromossomos dos pais s\u00e3o combinadas para criar novos indiv\u00edduos.</li> <li>Muta\u00e7\u00e3o: Pequenas altera\u00e7\u00f5es aleat\u00f3rias s\u00e3o feitas nos descendentes para manter diversidade gen\u00e9tica.</li> <li>Substitui\u00e7\u00e3o: Uma nova gera\u00e7\u00e3o substitui (total ou parcialmente) a antiga.</li> <li>Itera\u00e7\u00e3o: O processo se repete por v\u00e1rias gera\u00e7\u00f5es at\u00e9 que uma condi\u00e7\u00e3o de parada seja satisfeita (ex: n\u00famero m\u00e1ximo de gera\u00e7\u00f5es, solu\u00e7\u00e3o suficientemente boa, etc).</li> </ol>"},{"location":"portifolio-2/#contextos-de-aplicacao-dos-algoritmos-geneticos","title":"Contextos de Aplica\u00e7\u00e3o dos Algoritmos Gen\u00e9ticos","text":"<p>AGs s\u00e3o usados em problemas de otimiza\u00e7\u00e3o complexos, onde n\u00e3o h\u00e1 uma solu\u00e7\u00e3o exata vi\u00e1vel ou onde o espa\u00e7o de busca \u00e9 muito grande:</p>"},{"location":"portifolio-2/#exemplos-de-aplicacoes","title":"Exemplos de aplica\u00e7\u00f5es:","text":"<ul> <li>Otimiza\u00e7\u00e3o de rotas: problema do caixeiro viajante (TSP), roteamento de entregas.</li> <li>Agendamento: aloca\u00e7\u00e3o de tarefas em f\u00e1bricas ou escalas de funcion\u00e1rios.</li> <li>Design de redes neurais: otimiza\u00e7\u00e3o de hiperpar\u00e2metros de redes profundas.</li> <li>Engenharia: design de circuitos eletr\u00f4nicos, estruturas mec\u00e2nicas.</li> <li>Bioinform\u00e1tica: alinhamento de sequ\u00eancias gen\u00e9ticas, previs\u00e3o de estrutura de prote\u00ednas.</li> <li>Criptografia: quebra de cifras por tentativa evolutiva.</li> <li>Jogos e IA: criar NPCs adaptativos ou estrat\u00e9gias vencedoras.</li> </ul>"},{"location":"portifolio-2/#por-que-algoritmos-geneticos-sao-importantes","title":"Por que Algoritmos Gen\u00e9ticos s\u00e3o Importantes?","text":"<ul> <li>Robustez: Funcionam bem mesmo com fun\u00e7\u00f5es de custo n\u00e3o lineares, descont\u00ednuas ou com m\u00faltiplos \u00f3timos locais.</li> <li>Paralelismo natural: Por usar popula\u00e7\u00f5es, podem explorar v\u00e1rias solu\u00e7\u00f5es ao mesmo tempo.</li> <li>Generalidade: Podem ser aplicados a muitos tipos diferentes de problemas.</li> <li>N\u00e3o precisam de derivadas: Diferente do gradiente descendente, AGs n\u00e3o exigem fun\u00e7\u00f5es diferenci\u00e1veis.</li> </ul>"},{"location":"portifolio-2/#exemplos-de-algoritmos-geneticos-e-variantes","title":"Exemplos de Algoritmos Gen\u00e9ticos e Variantes","text":"<ol> <li>Algoritmo Gen\u00e9tico Cl\u00e1ssico (GA):<ul> <li>Baseado nos operadores b\u00e1sicos: sele\u00e7\u00e3o, crossover e muta\u00e7\u00e3o.</li> </ul> </li> <li>Algoritmo Gen\u00e9tico com Elitismo:<ul> <li>Garante que os melhores indiv\u00edduos de uma gera\u00e7\u00e3o sobrevivem \u00e0 pr\u00f3xima.</li> </ul> </li> <li>Algoritmos Gen\u00e9ticos Multiobjetivo (ex: NSGA-II):<ul> <li>Resolvem problemas com m\u00faltiplos crit\u00e9rios de otimiza\u00e7\u00e3o.</li> </ul> </li> <li>Algoritmos Evolutivos Diferenciais:<ul> <li>Variante que usa diferen\u00e7as entre solu\u00e7\u00f5es para gerar novas.</li> </ul> </li> <li>Algoritmos Gen\u00e9ticos com Codifica\u00e7\u00e3o Real:<ul> <li>Ao inv\u00e9s de bits, usam n\u00fameros reais (mais comum em otimiza\u00e7\u00e3o cont\u00ednua).</li> </ul> </li> </ol>"},{"location":"portifolio-2/#referencias","title":"Refer\u00eancias","text":"<ul> <li>RUSSELL, Stuart J.; NORVIG, Peter. Intelig\u00eancia Artificial. 3. ed. Rio de Janeiro: Elsevier, 2013.   (T\u00edtulo original: Artificial Intelligence: A Modern Approach)</li> <li>LUGER, George F. Intelig\u00eancia Artificial: estruturas e estrat\u00e9gias para a resolu\u00e7\u00e3o de problemas complexos. 6. ed. Pearson, 2009.</li> <li>GOLDBERG, David E. Algoritmos Gen\u00e9ticos em Busca, Otimiza\u00e7\u00e3o e Aprendizado de M\u00e1quina. Pearson Education, 1989.</li> <li>HOLLAND, John H. Adaptation in Natural and Artificial Systems. MIT Press, 1992.</li> <li>MITCHELL, Melanie. An Introduction to Genetic Algorithms. MIT Press, 1996.</li> <li>GOODFELLOW, Ian; BENGIO, Yoshua; COURVILLE, Aaron. Deep Learning. MIT Press, 2016. Dispon\u00edvel em: https://www.deeplearningbook.org/</li> <li>HASTIE, Trevor; TIBSHIRANI, Robert; FRIEDMAN, Jerome. The Elements of Statistical Learning. Springer, 2009.</li> <li>OpenAI Blog \u2013 AI concepts and research: https://openai.com/research</li> <li>Towards Data Science \u2013 Medium Publication: https://towardsdatascience.com/</li> <li>Geeks for Geeks \u2013 AI/ML tutorials: https://www.geeksforgeeks.org/fundamentals-of-artificial-intelligence/</li> <li>Stanford University \u2013 AI Course Materials: https://cs221.stanford.edu/</li> </ul>"},{"location":"portifolio-3/","title":"Portf\u00f3lio 3 - Constraint Satisfaction Problems - CSP","text":""},{"location":"portifolio-3/#introducao-aos-csps","title":"Introdu\u00e7\u00e3o aos CSPs","text":"<p>Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (CSPs), trata-se de uma classe de problemas onde o objetivo \u00e9 encontrar valores para um conjunto de vari\u00e1veis que satisfa um conjunto de restri\u00e7\u00f5es. Formalmente, um CSP consiste em:</p> <ul> <li>Um conjunto de vari\u00e1veis X = {X\u2081, X\u2082, ..., X\u2099}</li> <li>Um conjunto de dom\u00ednios D = {D\u2081, D\u2082, ..., D\u2099}, onde cada D\u1d62 \u00e9 o conjunto de valores poss\u00edveis para X\u1d62</li> <li>Um conjunto de restri\u00e7\u00f5es C = {C\u2081, C\u2082, ..., C\u2098} que especificam combina\u00e7\u00f5es v\u00e1lidas de valores</li> </ul>"},{"location":"portifolio-3/#11-exemplo-pratico-solucionador-de-sudoku-simples-usando-csp","title":"1.1 Exemplo Pr\u00e1tico: Solucionador de Sudoku Simples usando CSP","text":"<p>Neste exemplo, implemento um solucionador de Sudoku utilizando t\u00e9cnicas de CSP.</p> <ul> <li>Vari\u00e1veis: 81 c\u00e9lulas do tabuleiro (9x9)</li> <li>Dom\u00ednios: N\u00fameros de 1 a 9 para cada c\u00e9lula</li> <li>Restri\u00e7\u00f5es: </li> <li>Cada linha cont\u00e9m n\u00fameros \u00fanicos de 1 a 9</li> <li>Cada coluna cont\u00e9m n\u00fameros \u00fanicos de 1 a 9</li> <li>Cada subgrade 3x3 cont\u00e9m n\u00fameros \u00fanicos de 1 a 9</li> </ul> Python<pre><code>class SudokuCSP:\n    def __init__(self, board):\n        self.board = board\n        self.variables = [(i, j) for i in range(9) for j in range(9)]\n        self.domains = {var: set(range(1, 10)) for var in self.variables}\n        self.constraints = self._get_constraints()\n\n    def _get_constraints(self):\n        constraints = []\n        # Restri\u00e7\u00f5es de linha\n        for i in range(9):\n            for j in range(9):\n                for k in range(j + 1, 9):\n                    constraints.append(((i, j), (i, k)))\n\n        # Restri\u00e7\u00f5es de coluna\n        for j in range(9):\n            for i in range(9):\n                for k in range(i + 1, 9):\n                    constraints.append(((i, j), (k, j)))\n\n        # Restri\u00e7\u00f5es de subgrade 3x3\n        for block_i in range(3):\n            for block_j in range(3):\n                cells = [(3*block_i + i, 3*block_j + j) \n                        for i in range(3) for j in range(3)]\n                for i, cell1 in enumerate(cells):\n                    for cell2 in cells[i+1:]:\n                        constraints.append((cell1, cell2))\n\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        for neighbor in self.get_neighbors(var):\n            if neighbor in assignment and assignment[neighbor] == value:\n                return False\n        return True\n\n    def get_neighbors(self, var):\n        neighbors = set()\n        for constraint in self.constraints:\n            if var in constraint:\n                neighbors.add(constraint[1] if constraint[0] == var else constraint[0])\n        return neighbors\n</code></pre>"},{"location":"portifolio-3/#estrategias-de-resolucao-de-csps","title":"Estrat\u00e9gias de Resolu\u00e7\u00e3o de CSPs","text":""},{"location":"portifolio-3/#1-backtracking-search","title":"1. Backtracking Search","text":"<p>T\u00e9cnica fundamental para resolver CSPs. Consiste em tentar atribuir valores \u00e0s vari\u00e1veis uma por uma, voltando atr\u00e1s quando encontra um conflito.</p> Python<pre><code>def backtracking_search(csp):\n    def backtrack(assignment):\n        if len(assignment) == len(csp.variables):\n            return assignment\n\n        var = select_unassigned_variable(csp, assignment)\n        for value in order_domain_values(csp, var, assignment):\n            if csp.is_consistent(var, value, assignment):\n                assignment[var] = value\n                result = backtrack(assignment)\n                if result is not None:\n                    return result\n                del assignment[var]\n        return None\n\n    return backtrack({})\n</code></pre>"},{"location":"portifolio-3/#2-forward-checking","title":"2. Forward Checking","text":"<p>T\u00e9cnica de propaga\u00e7\u00e3o de restri\u00e7\u00f5es que mant\u00e9m a consist\u00eancia dos dom\u00ednios das vari\u00e1veis n\u00e3o atribu\u00eddas.</p> Python<pre><code>def forward_checking(csp, var, value, assignment, domains):\n    for neighbor in csp.get_neighbors(var):\n        if neighbor not in assignment:\n            if value in domains[neighbor]:\n                domains[neighbor].remove(value)\n                if not domains[neighbor]:\n                    return False\n    return True\n</code></pre>"},{"location":"portifolio-3/#estrategias-de-selecao-de-variaveis","title":"Estrat\u00e9gias de Sele\u00e7\u00e3o de Vari\u00e1veis","text":""},{"location":"portifolio-3/#1-minimum-remaining-values-mrv","title":"1. Minimum Remaining Values (MRV)","text":"<p>Seleciona a vari\u00e1vel com o menor n\u00famero de valores poss\u00edveis no dom\u00ednio.</p> Python<pre><code>def select_unassigned_variable_mrv(csp, assignment):\n    unassigned = [var for var in csp.variables if var not in assignment]\n    return min(unassigned, key=lambda var: len(csp.domains[var]))\n</code></pre>"},{"location":"portifolio-3/#2-degree-heuristic","title":"2. Degree Heuristic","text":"<p>Seleciona a vari\u00e1vel que est\u00e1 envolvida no maior n\u00famero de restri\u00e7\u00f5es com outras vari\u00e1veis n\u00e3o atribu\u00eddas.</p> Python<pre><code>def select_unassigned_variable_degree(csp, assignment):\n    unassigned = [var for var in csp.variables if var not in assignment]\n    return max(unassigned, key=lambda var: len(csp.get_neighbors(var)))\n</code></pre>"},{"location":"portifolio-3/#estrategias-de-ordenacao-de-valores","title":"Estrat\u00e9gias de Ordena\u00e7\u00e3o de Valores","text":""},{"location":"portifolio-3/#1-least-constraining-value-lcv","title":"1. Least Constraining Value (LCV)","text":"<p>Ordena os valores de forma a minimizar o impacto nas outras vari\u00e1veis.</p> Python<pre><code>def order_domain_values_lcv(csp, var, assignment):\n    def count_conflicts(value):\n        conflicts = 0\n        for neighbor in csp.get_neighbors(var):\n            if neighbor not in assignment and value in csp.domains[neighbor]:\n                conflicts += 1\n        return conflicts\n\n    return sorted(csp.domains[var], key=count_conflicts)\n</code></pre>"},{"location":"portifolio-3/#contribuicoes-e-melhorias","title":"Contribui\u00e7\u00f5es e Melhorias","text":""},{"location":"portifolio-3/#1-algoritmo-de-consistencia-de-arco-ac-3","title":"1. Algoritmo de Consist\u00eancia de Arco (AC-3)","text":"<p>Implementa\u00e7\u00e3o do algoritmo AC-3 para manter a consist\u00eancia de arco:</p> Python<pre><code>def ac3(csp):\n    queue = csp.constraints.copy()\n    while queue:\n        (xi, xj) = queue.pop()\n        if revise(csp, xi, xj):\n            if not csp.domains[xi]:\n                return False\n            for xk in csp.get_neighbors(xi):\n                if xk != xj:\n                    queue.append((xk, xi))\n    return True\n\ndef revise(csp, xi, xj):\n    revised = False\n    for x in csp.domains[xi].copy():\n        if not any(csp.is_consistent(xi, x, {xj: y}) for y in csp.domains[xj]):\n            csp.domains[xi].remove(x)\n            revised = True\n    return revised\n</code></pre>"},{"location":"portifolio-3/#2-algoritmo-de-busca-local","title":"2. Algoritmo de Busca Local","text":"<p>Implementa\u00e7\u00e3o de um algoritmo de busca local para CSPs:</p> Python<pre><code>def min_conflicts(csp, max_steps=1000):\n    assignment = {var: random.choice(list(csp.domains[var])) \n                 for var in csp.variables}\n\n    for _ in range(max_steps):\n        if is_solution(csp, assignment):\n            return assignment\n\n        var = select_conflicted_variable(csp, assignment)\n        value = min_conflicts_value(csp, var, assignment)\n        assignment[var] = value\n\n    return None\n\ndef select_conflicted_variable(csp, assignment):\n    conflicted = []\n    for var in csp.variables:\n        if not csp.is_consistent(var, assignment[var], assignment):\n            conflicted.append(var)\n    return random.choice(conflicted)\n\ndef min_conflicts_value(csp, var, assignment):\n    return min(csp.domains[var], \n              key=lambda value: count_conflicts(csp, var, value, assignment))\n</code></pre>"},{"location":"portifolio-3/#analise-de-desempenho","title":"An\u00e1lise de Desempenho","text":"<p>Nas diferentes estrat\u00e9gias utilizadas, realizamos testes com v\u00e1rios tabuleiros de Sudoku:</p> <ol> <li>Backtracking com MRV + LCV: </li> <li>Mais eficiente para problemas pequenos</li> <li>Garante solu\u00e7\u00e3o \u00f3tima</li> <li> <p>Pode ser lento para problemas grandes</p> </li> <li> <p>Forward Checking:</p> </li> <li>Reduz significativamente o n\u00famero de backtrackings</li> <li>Melhor para problemas com muitas restri\u00e7\u00f5es</li> <li> <p>Custo adicional de manuten\u00e7\u00e3o dos dom\u00ednios</p> </li> <li> <p>AC-3:</p> </li> <li>Muito eficiente para problemas com restri\u00e7\u00f5es bin\u00e1rias</li> <li>Pode resolver alguns problemas sem backtracking</li> <li> <p>Custo computacional maior</p> </li> <li> <p>Min-Conflicts:</p> </li> <li>Excelente para problemas grandes</li> <li>N\u00e3o garante solu\u00e7\u00e3o \u00f3tima</li> <li>Muito r\u00e1pido em m\u00e9dia</li> </ol>"},{"location":"portifolio-3/#demais-exemplos-praticos","title":"Demais Exemplos Pr\u00e1ticos","text":""},{"location":"portifolio-3/#2-problema-das-n-rainhas-n-queens","title":"2. Problema das N-Rainhas (N-Queens)","text":"<p>O objetivo deste problema \u00e9 posicionar N rainhas em um tabuleiro NxN de forma que nenhuma rainha possa atacar outra.</p> Python<pre><code>class NQueensCSP:\n    def __init__(self, n):\n        self.n = n\n        self.variables = list(range(n))  # Cada vari\u00e1vel representa uma coluna\n        self.domains = {var: list(range(n)) for var in self.variables}\n        self.constraints = self._get_constraints()\n\n    def _get_constraints(self):\n        constraints = []\n        for i in range(self.n):\n            for j in range(i + 1, self.n):\n                constraints.append((i, j))\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        for col, row in assignment.items():\n            if col == var:\n                continue\n            # Verifica ataques na mesma linha\n            if row == value:\n                return False\n            # Verifica ataques nas diagonais\n            if abs(col - var) == abs(row - value):\n                return False\n        return True\n</code></pre>"},{"location":"portifolio-3/#3-problema-de-coloracao-de-mapas-map-coloring","title":"3. Problema de Colora\u00e7\u00e3o de Mapas (Map Coloring)","text":"<p>Um problema onde o objetivo \u00e9 colorir um mapa com um n\u00famero m\u00ednimo de cores, para garantir que regi\u00f5es adjacentes tenham cores diferentes.</p> Python<pre><code>class MapColoringCSP:\n    def __init__(self, regions, adjacencies, colors):\n        self.variables = regions\n        self.domains = {var: set(colors) for var in self.variables}\n        self.constraints = self._get_constraints(adjacencies)\n\n    def _get_constraints(self, adjacencies):\n        constraints = []\n        for region1, neighbors in adjacencies.items():\n            for region2 in neighbors:\n                if (region2, region1) not in constraints:\n                    constraints.append((region1, region2))\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        for neighbor in self.get_neighbors(var):\n            if neighbor in assignment and assignment[neighbor] == value:\n                return False\n        return True\n</code></pre>"},{"location":"portifolio-3/#4-problema-de-horarios-scheduling","title":"4. Problema de Hor\u00e1rios (Scheduling)","text":"<p>Um problema comum em escolas e universidades para criar hor\u00e1rios de aulas, evitando conflitos de professores, salas e turmas.</p> Python<pre><code>class SchedulingCSP:\n    def __init__(self, classes, teachers, rooms, time_slots):\n        self.variables = classes\n        self.domains = {\n            var: [(room, time) for room in rooms for time in time_slots]\n            for var in self.variables\n        }\n        self.teacher_assignments = {class_: teacher for class_, teacher in teachers}\n        self.constraints = self._get_constraints()\n\n    def _get_constraints(self):\n        constraints = []\n        # Restri\u00e7\u00f5es de professor\n        for class1 in self.variables:\n            for class2 in self.variables:\n                if class1 &lt; class2:\n                    if self.teacher_assignments[class1] == self.teacher_assignments[class2]:\n                        constraints.append((class1, class2))\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        room, time = value\n        # Verifica conflito de sala\n        for class_, (r, t) in assignment.items():\n            if r == room and t == time:\n                return False\n        # Verifica conflito de professor\n        teacher = self.teacher_assignments[var]\n        for class_, (r, t) in assignment.items():\n            if t == time and self.teacher_assignments[class_] == teacher:\n                return False\n        return True\n</code></pre>"},{"location":"portifolio-3/#5-problema-de-roteamento-de-veiculos-vehicle-routing","title":"5. Problema de Roteamento de Ve\u00edculos (Vehicle Routing)","text":"<p>Um problema de otimiza\u00e7\u00e3o onde o objetivo \u00e9 encontrar rotas \u00f3timas para uma frota de ve\u00edculos atendendo a um conjunto de clientes.</p> Python<pre><code>class VehicleRoutingCSP:\n    def __init__(self, customers, vehicles, capacity_constraints):\n        self.variables = customers\n        self.domains = {\n            var: [(v, pos) for v in vehicles for pos in range(len(customers))]\n            for var in self.variables\n        }\n        self.capacity_constraints = capacity_constraints\n        self.constraints = self._get_constraints()\n\n    def _get_constraints(self):\n        constraints = []\n        # Restri\u00e7\u00f5es de capacidade\n        for v in self.vehicles:\n            customer_assignments = [c for c in self.variables \n                                 if self.domains[c][0] == v]\n            if sum(self.capacity_constraints[c] for c in customer_assignments) &gt; v.capacity:\n                constraints.append(customer_assignments)\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        vehicle, position = value\n        # Verifica capacidade\n        current_load = sum(self.capacity_constraints[c] \n                         for c, (v, _) in assignment.items() \n                         if v == vehicle)\n        if current_load + self.capacity_constraints[var] &gt; vehicle.capacity:\n            return False\n        # Verifica posi\u00e7\u00e3o\n        for c, (v, pos) in assignment.items():\n            if v == vehicle and pos == position:\n                return False\n        return True\n</code></pre>"},{"location":"portifolio-3/#6-problema-de-montagem-de-produtos-assembly-line-balancing","title":"6. Problema de Montagem de Produtos (Assembly Line Balancing)","text":"<p>Um problema de otimiza\u00e7\u00e3o onde o objetivo \u00e9 distribuir tarefas de montagem entre esta\u00e7\u00f5es de trabalho, para minimizar o tempo total de ciclo.</p> Python<pre><code>class AssemblyLineCSP:\n    def __init__(self, tasks, stations, task_times, precedences):\n        self.variables = tasks\n        self.domains = {var: list(range(stations)) for var in self.variables}\n        self.task_times = task_times\n        self.precedences = precedences\n        self.constraints = self._get_constraints()\n\n    def _get_constraints(self):\n        constraints = []\n        # Restri\u00e7\u00f5es de preced\u00eancia\n        for task1, task2 in self.precedences:\n            constraints.append((task1, task2))\n        return constraints\n\n    def is_consistent(self, var, value, assignment):\n        # Verifica preced\u00eancia\n        for task1, task2 in self.precedences:\n            if task1 == var and task2 in assignment:\n                if assignment[task2] &lt;= value:\n                    return False\n            elif task2 == var and task1 in assignment:\n                if assignment[task1] &gt;= value:\n                    return False\n        # Verifica tempo de ciclo\n        station_time = sum(self.task_times[t] \n                         for t, s in assignment.items() \n                         if s == value)\n        if station_time + self.task_times[var] &gt; self.cycle_time:\n            return False\n        return True\n</code></pre>"},{"location":"portifolio-3/#conclusao","title":"Conclus\u00e3o","text":"<p>Cada um desses projetos demonstra diferentes aspectos dos CSPs:</p> <ol> <li>Solucionador de Sudoku: Demonstra restri\u00e7\u00f5es complexas em ambiente multivariavel, como exclusividade de valores em linhas, colunas e blocos 3x3</li> <li>N-Rainhas: Demonstra restri\u00e7\u00f5es bin\u00e1rias simples e sim\u00e9tricas, em que nenhuma rainha pode atacar outra na mesma linha, coluna ou diagonal.</li> <li>Colora\u00e7\u00e3o de Mapas: Mostra como modelar problemas com restri\u00e7\u00f5es de adjac\u00eancia, onde regi\u00f5es vizinhas n\u00e3o podem ter a mesma cor.</li> <li>Scheduling: Representa\u00e7\u00e3o de problemas com restri\u00e7\u00f5es m\u00faltiplas e heterog\u00eaneas, como conflitos de hor\u00e1rio, recursos limitados (salas, professores) e prefer\u00eancias.</li> <li>Roteamento de Ve\u00edculos: Envolve restri\u00e7\u00f5es de capacidade, tempo e sequ\u00eancia, como limite de carga dos ve\u00edculos e janelas de entrega.</li> <li>Montagem de Produtos: Demonstra restri\u00e7\u00f5es de preced\u00eancia, sincroniza\u00e7\u00e3o e tempo, comuns em ambientes industriais e de produ\u00e7\u00e3o.</li> </ol> <p>Dessa forma, os Problemas de Satisfa\u00e7\u00e3o de Restri\u00e7\u00f5es (CSPs) demonstram ser uma ferramenta poderosa para modelar e resolver uma ampla variedade de problemas que envolvem restri\u00e7\u00f5es complexas. Durante a an\u00e1lise e desenvolvimento de solu\u00e7\u00f5es baseadas em CSPs, observou-se a import\u00e2ncia da escolha adequada das estrat\u00e9gias de sele\u00e7\u00e3o de vari\u00e1veis e valores, visto que essas decis\u00f5es influenciam diretamente a efici\u00eancia e a viabilidade da resolu\u00e7\u00e3o. Al\u00e9m disso, as t\u00e9cnicas de propaga\u00e7\u00e3o de restri\u00e7\u00f5es mostraram ter um impacto significativo na redu\u00e7\u00e3o do espa\u00e7o de busca, permitindo identificar inconsist\u00eancias precocemente e, assim, acelerar o processo de resolu\u00e7\u00e3o. Tamb\u00e9m foi poss\u00edvel perceber que diferentes algoritmos apresentam desempenhos distintos dependendo do contexto e da estrutura do problema, o que refor\u00e7a a necessidade de uma an\u00e1lise criteriosa para a sele\u00e7\u00e3o do m\u00e9todo mais apropriado.</p> <p>Entre as contribui\u00e7\u00f5es desenvolvidas ao longo do projeto, destacam-se a implementa\u00e7\u00e3o de m\u00faltiplas estrat\u00e9gias de resolu\u00e7\u00e3o, a realiza\u00e7\u00e3o de uma an\u00e1lise comparativa de desempenho entre essas estrat\u00e9gias e a adapta\u00e7\u00e3o de abordagens espec\u00edficas para problemas cl\u00e1ssicos, como o Sudoku, demonstrando a flexibilidade e aplicabilidade dos CSPs em cen\u00e1rios diversos.</p>"},{"location":"portifolio-3/#referencias","title":"Refer\u00eancias","text":"<ol> <li>Russell, S., &amp; Norvig, P. (2020). Artificial Intelligence: A Modern Approach (4\u00aa ed.). Pearson.</li> <li>Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.</li> <li>Kumar, V. (1992). Algorithms for Constraint Satisfaction Problems: A Survey. AI Magazine, 13(1), 32\u201344.</li> <li>Mackworth, A. K. (1977). Consistency in networks of relations. Artificial Intelligence, 8(1), 99\u2013118.</li> <li>Haralick, R. M., &amp; Elliott, G. L. (1980). Increasing tree search efficiency for constraint satisfaction problems. Artificial Intelligence, 14(3), 263\u2013313.</li> <li>Bessiere, C. (2006). Constraint propagation. In Handbook of Constraint Programming, Elsevier, 29\u201383.</li> <li>Apt, K. R. (2003). Principles of Constraint Programming. Cambridge University Press.</li> <li>Rossi, F., van Beek, P., &amp; Walsh, T. (Eds.). (2006). Handbook of Constraint Programming. Elsevier.</li> </ol>"},{"location":"portifolio-4/","title":"Portif\u00f3lio 4","text":""},{"location":"portifolio-4/#agentes-logicos","title":"Agentes L\u00f3gicos","text":"<p>Os agentes l\u00f3gicos ou tamb\u00e9m denominados agentes baseados em conhecimento, representam uma categoria fundamental de agentes artificiais empregando a l\u00f3gica formal como alicerce para a representar conhecimento e racioc\u00ednio. Em sua arquitetura, h\u00e1 concebi\u00e7\u00e3o que possibilita a tomada de decis\u00f5es fundamentadas numa compreens\u00e3o estruturada e inferencial do ambiente, o que diferencia significativamente dos agentes puramente reativos, que operam com base em respostas diretas a est\u00edmulos imediatos.</p>"},{"location":"portifolio-4/#representacao-do-conhecimento-a-fundacao-dos-agentes-logicos","title":"Representa\u00e7\u00e3o do Conhecimento: A Funda\u00e7\u00e3o dos Agentes L\u00f3gicos","text":"<p>Um agente l\u00f3gico, tem como capacidade central a Representa\u00e7\u00e3o do Conhecimento. Por sua vez, este \u00e9 componente que busca permitir que o agente codifique informa\u00e7\u00f5es sobre o mundo de forma expl\u00edcita e simb\u00f3lica, utilizando linguagens formais baseadas em l\u00f3gica, predominantemente a l\u00f3gica proposicional e a l\u00f3gica de primeira ordem (LPO).</p> <ul> <li> <p>L\u00f3gica Proposicional: Utiliza\u00e7\u00e3o de proposi\u00e7\u00f5es (afirma\u00e7\u00f5es que podem ser verdadeiras ou falsas, dependendo do contexto) e conectivos l\u00f3gicos como \"e\" (and), \"ou\" (or), \"n\u00e3o\" (not), \"implica\" (if...then) e \"se e somente se\" (iff) na constru\u00e7\u00e3o de senten\u00e7as complexas. \u00c9 \u00fatil para representar fatos at\u00f4micos e suas inter-rela\u00e7\u00f5es booleanas.   Exemplo: \"\u00c9 dia\" e \"Est\u00e1 sol\" implica \"Vou \u00e0 praia\".</p> </li> <li> <p>L\u00f3gica de Primeira Ordem (LPO): Expande a l\u00f3gica proposicional introduzindo predicados, vari\u00e1veis, quantificadores como \"para todo\" e \"existe\", al\u00e9m de fun\u00e7\u00f5es. Isso confere \u00e0 LPO um poder de express\u00e3o muito maior que permite representar rela\u00e7\u00f5es entre objetos, propriedades de objetos e generaliza\u00e7\u00f5es.   Exemplo: Para toda pessoa x, se x \u00e9 uma pessoa, ent\u00e3o x \u00e9 mortal.   \u00c9 uma capacidade crucial para modelar ambientes complexos, onde h\u00e1 entidades, atributos e rela\u00e7\u00f5es que precisam ser representados com diferentes n\u00edveis de detalhamento.</p> </li> </ul> <p>A partir disso, o conhecimento \u00e9 armazenado numa Base de Conhecimento (BC), sendo um conjunto de senten\u00e7as (axiomas e fatos) expressas na linguagem l\u00f3gica escolhida. Cada senten\u00e7a na Base de Conhecimento contribui para a compreens\u00e3o do agente sobre o estado do ambiente e as regras que o governam.</p>"},{"location":"portifolio-4/#mecanismo-de-inferencia-o-raciocinio-dedutivo","title":"Mecanismo de Infer\u00eancia: O Racioc\u00ednio Dedutivo","text":"<p>O Mecanismo de Infer\u00eancia \u00e9 o motor do racioc\u00ednio em um agente baseado em conhecimento. Ele busca operar sobre a Base de Conhecimento, aplicando regras de infer\u00eancia que deduzam novas senten\u00e7as (conclus\u00f5es) a partir de senten\u00e7as existentes. Este processo \u00e9 an\u00e1logo ao racioc\u00ednio humano, onde novas verdades s\u00e3o derivadas de premissas conhecidas.</p> <ul> <li>Regras de Infer\u00eancia: S\u00e3o procedimentos formais que garantem que, se as premissas forem verdadeiras, a conclus\u00e3o derivada tamb\u00e9m ser\u00e1. Exemplos comuns incluem:<ul> <li>Modus Ponens: Se tivermos as senten\u00e7as \\(A\\) e \\(A \\Rightarrow B\\), podemos inferir \\(B\\).</li> <li>Resolu\u00e7\u00e3o: Um m\u00e9todo de infer\u00eancia completo e semi-decid\u00edvel para a LPO, amplamente utilizado em provadores de teoremas automatizados.</li> </ul> </li> <li>Completude e Decidibilidade: A escolha de um sistema l\u00f3gico e das regras de infer\u00eancia impactam a completude (se todas as verdades podem ser provadas) e a decidibilidade (se existe um algoritmo que sempre termina e determina a verdade de qualquer senten\u00e7a). A l\u00f3gica proposicional \u00e9 decid\u00edvel, enquanto a LPO \u00e9 semi-decid\u00edvel (se uma senten\u00e7a \u00e9 verdadeira, o algoritmo eventualmente a provar\u00e1; se for falsa, pode n\u00e3o terminar).</li> <li>Busca: O processo de infer\u00eancia, muitas vezes envolve uma busca heur\u00edstica ou algor\u00edtmica no espa\u00e7o de estados para encontrar uma prova ou uma solu\u00e7\u00e3o para uma consulta. Algoritmos como busca em largura (BFS), busca em profundidade (DFS) e A* podem ser adaptados para atender a este prop\u00f3sito.</li> </ul>"},{"location":"portifolio-4/#robustez-em-ambientes-parcialmente-observaveis-e-dinamicos","title":"Robustez em Ambientes Parcialmente Observ\u00e1veis e Din\u00e2micos","text":"<p>Uma das grandes vantagens dos agentes l\u00f3gicos \u00e9 a sua aptid\u00e3o para operar em ambientes parcialmente observ\u00e1veis. Nesses cen\u00e1rios, nem todas as informa\u00e7\u00f5es relevantes est\u00e3o diretamente acess\u00edveis atrav\u00e9s dos sensores do agente. Sendo assim, o agente l\u00f3gico compensa essa limita\u00e7\u00e3o ao utilizar seu conhecimento pr\u00e9vio e suas capacidades de infer\u00eancia para deduzir o estado oculto do mundo ou prever eventos futuros. Por exemplo, se um sensor falha, o agente pode inferir a probabilidade de um evento com base em outras observa\u00e7\u00f5es e no conhecimento das leis do dom\u00ednio.</p> <p>A flexibilidade e adaptabilidade s\u00e3o caracter\u00edsticas intr\u00ednsecas devido \u00e0 natureza expl\u00edcita da Base de Conhecimento. Pois altera\u00e7\u00f5es no ambiente ou nos objetivos do agente podem ser acomodadas atrav\u00e9s da modifica\u00e7\u00e3o ou adi\u00e7\u00e3o de senten\u00e7as l\u00f3gicas \u00e0 Base de conhecimento, sem a necessidade de reengenharia completa do agente. Essa modularidade tende a facilitar a manuten\u00e7\u00e3o e a evolu\u00e7\u00e3o do sistema.</p>"},{"location":"portifolio-4/#raciocinio-proativo-e-planejamento-orientado-a-metas","title":"Racioc\u00ednio Proativo e Planejamento Orientado a Metas","text":"<p>OS agentes puramente reativos, respondem a est\u00edmulos de forma condicionada. Por\u00e9m, os agentes l\u00f3gicos exibem racioc\u00ednio proativo e orientado a metas. Essa diferen\u00e7a, garante a capacidade de formular planos complexos, que s\u00e3o sequ\u00eancias de a\u00e7\u00f5es, para alcan\u00e7ar objetivos definidos. Este processo de planejamento envolve:</p> <ol> <li>Definir o Estado Inicial: Conhecimento atual do agente sobre o mundo.</li> <li>Definir o Estado Objetivo: Configura\u00e7\u00e3o desejada do mundo que o agente busca alcan\u00e7ar.</li> <li>A\u00e7\u00f5es: Descri\u00e7\u00e3o das a\u00e7\u00f5es que o agente pode executar e seus efeitos no mundo (condi\u00e7\u00f5es de pr\u00e9-requisito e p\u00f3s-condi\u00e7\u00f5es).</li> <li>Buscar o Espa\u00e7o de Estados: Mecanismo de infer\u00eancia, busca uma sequ\u00eancia de a\u00e7\u00f5es que transforme o estado inicial no estado objetivo, e que considere as regras e restri\u00e7\u00f5es do ambiente. Algoritmos de planejamento como STRIPS, ADL, ou t\u00e9cnicas de Graphplan e SAT-based planning s\u00e3o empregados para este fim.</li> </ol>"},{"location":"portifolio-4/#ciclo-operacional-de-um-agente-logico","title":"Ciclo Operacional de um Agente L\u00f3gico","text":"<p>O funcionamento de um agente l\u00f3gico pode ser encapsulado em um ciclo iterativo:</p> <ol> <li>Percep\u00e7\u00e3o: Recebimento de novas percep\u00e7\u00f5es do ambiente atrav\u00e9s de seus respectivos sensores. Essas percep\u00e7\u00f5es, s\u00e3o convertidas em senten\u00e7as l\u00f3gicas e adicionadas \u00e0 Base de Conhecimento.</li> <li>Atualiza\u00e7\u00e3o da Base de Conhecimento (KB update): Atualiza\u00e7\u00e3o da Base de Conhecimento incorpotando as novas percep\u00e7\u00f5es, garantindo que o conhecimento do agente reflita o estado atual do ambiente. Isso pode envolver adi\u00e7\u00e3o, modifica\u00e7\u00e3o ou remo\u00e7\u00e3o de senten\u00e7as.</li> <li>Racioc\u00ednio/Infer\u00eancia: O mecanismo de infer\u00eancia tem o objetivo de processar a Base de Conhecimento para:<ul> <li>Derivar novas verdades sobre o ambiente.</li> <li>Responder a consultas (e.g., \"Qual \u00e9 a melhor a\u00e7\u00e3o a tomar?\").</li> <li>Detectar inconsist\u00eancias.</li> <li>Gerar um plano de a\u00e7\u00f5es para alcan\u00e7ar um objetivo espec\u00edfico.</li> </ul> </li> <li>A\u00e7\u00e3o: Com base nas conclus\u00f5es do racioc\u00ednio, o agente busca seleciona e executa uma a\u00e7\u00e3o no ambiente atrav\u00e9s de seus atuadores. Esta a\u00e7\u00e3o pode alterar o estado do ambiente e gerar novas percep\u00e7\u00f5es no pr\u00f3ximo ciclo.</li> </ol>"},{"location":"portifolio-4/#aplicacoes-e-relevancia","title":"Aplica\u00e7\u00f5es e Relev\u00e2ncia","text":"<p>Agentes l\u00f3gicos s\u00e3o fundamentais em diversas \u00e1reas da IA:</p> <ul> <li>Sistemas Especialistas: Utilizam bases de conhecimento extensas e regras de infer\u00eancia que emulam o racioc\u00ednio de especialistas humanos em dom\u00ednios espec\u00edficos (e.g., diagn\u00f3stico m\u00e9dico, configura\u00e7\u00e3o de sistemas).</li> <li>Planejamento Automatizado: Desenvolvimento de sequ\u00eancias de a\u00e7\u00f5es para rob\u00f4s, sistemas aut\u00f4nomos ou para gerenciar projetos complexos.</li> <li>Processamento de Linguagem Natural: A l\u00f3gica de primeira ordem pode ser usada na representa\u00e7\u00e3o do significado sem\u00e2ntico de frases, permitindo que m\u00e1quinas compreendam e raciocinem sobre o texto.</li> <li>Representa\u00e7\u00e3o de Conhecimento na Web Sem\u00e2ntica: Fundamentam tecnologias como ontologias e linguagens como OWL permitindo que m\u00e1quinas entendam o significado dos dados na web.</li> </ul>"},{"location":"portifolio-4/#referencias","title":"Refer\u00eancias","text":"<ul> <li>RUSSELL, Stuart J.; NORVIG, Peter. Intelig\u00eancia Artificial. 3. ed. Rio de Janeiro: Elsevier, 2013. (T\u00edtulo original: Artificial Intelligence: A Modern Approach)</li> <li>LUGER, George F. Intelig\u00eancia Artificial: estruturas e estrat\u00e9gias para a resolu\u00e7\u00e3o de problemas complexos. 6. ed. Pearson, 2009.</li> <li>NILSSON, Nils J. Artificial Intelligence: A New Synthesis. Morgan Kaufmann, 1998.</li> <li>BRATKO, Ivan. Prolog Programming for Artificial Intelligence. 4. ed. Pearson Education, 2011.</li> </ul>"},{"location":"portifolio-5/","title":"Portf\u00f3lio 5: Racioc\u00ednio Probabil\u00edstico e Estima\u00e7\u00e3o de Estados","text":""},{"location":"portifolio-5/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Esta parte do portf\u00f3lio busca explorar os conceitos fundamentais em Intelig\u00eancia Artificial que lidam com a incerteza, realizam infer\u00eancia e estimam estados em ambientes din\u00e2micos. Ser\u00e1 abordado a quantifica\u00e7\u00e3o da incerteza e o poder das Redes Bayesianas, passando pelo racioc\u00ednio probabil\u00edstico ao longo do tempo, at\u00e9 os Filtros de Kalman para estima\u00e7\u00e3o \u00f3tima de estados.</p>"},{"location":"portifolio-5/#1-quantificando-incertezas-e-redes-bayesianas","title":"1. Quantificando Incertezas e Redes Bayesianas","text":"<p>Os Agentes de IA no mundo real, por sua vez, precisam lidar com a incerteza. Esse fator, ocorre devido a fatores como a observabilidade parcial do ambiente, o n\u00e3o determinismo das a\u00e7\u00f5es ou presen\u00e7a de advers\u00e1rios. Uma abordagem inicial, sendo vista em agentes l\u00f3gicos, \u00e9 envolver o acompanhamento de todos os estados de mundo poss\u00edveis, mas essa estrat\u00e9gia tende a possuir desvantagens significativas em problemas complexos:</p> <ul> <li>O agente precisaria considerar e armazenar todas as explica\u00e7\u00f5es poss\u00edveis para as suas observa\u00e7\u00f5es, mesmo as observa\u00e7\u00f5es mais improv\u00e1veis.</li> <li>Um plano de conting\u00eancia que consiga lidar com todas as eventualidades e possa crescer arbitrariamente e incluir conting\u00eancias muito improv\u00e1veis.</li> <li>Em alguns casos, n\u00e3o h\u00e1 um plano que garanta o alcance da meta, exigindo que o agente compare os m\u00e9ritos de planos n\u00e3o garantidos.</li> </ul> <p>Para ilustrarmos, imagine um agente de um modelo de Smart Taxi que precisa levar um cliente ao aeroporto para um voo \u00e0s 21h, exigindo que a chegada seja \u00e0s 20h. O tempo de viagem poder\u00e1 variar (30 min em tr\u00e2nsito m\u00e9dio, 45 min em pesado, 20 min em leve) dependendo do hor\u00e1rio e condi\u00e7\u00f5es clim\u00e1ticas (chuva, por exemplo, sempre significa tr\u00e2nsito pesado). Al\u00e9m disso, h\u00e1 uma chance de acidentes na rota, aumentando o tempo de viagem. Qual seria o melhor plano para chegar com seguran\u00e7a? A incerteza nesse caso \u00e9 clara.</p> <p>Outro exemplo \u00e9 o diagn\u00f3stico odontol\u00f3gico. Uma regra l\u00f3gica simples como \"Dor de dente -&gt; C\u00e1rie\" \u00e9 incorreta, pois nem toda dor de dente \u00e9 ou ser\u00e1 c\u00e1rie. Para torn\u00e1-la correta, seria necess\u00e1rio listar todas as qualifica\u00e7\u00f5es (exce\u00e7\u00f5es e condi\u00e7\u00f5es) para que uma c\u00e1rie cause dor de dente, o que \u00e9 impratic\u00e1vel. Tentar usar essa l\u00f3gica para dom\u00ednios como diagn\u00f3stico m\u00e9dico \u00e9 dif\u00edcil por tr\u00eas raz\u00f5es:</p> <ul> <li>Complexidade: \u00c9 um trabalho \u00e1rduo listar o conjunto completo de antecedentes ou consequentes que garanta uma regra sem exce\u00e7\u00f5es.</li> <li>Ignor\u00e2ncia te\u00f3rica: A ci\u00eancia m\u00e9dica, por exemplo, n\u00e3o possui uma teoria completa para seu dom\u00ednio.</li> <li>Ignor\u00e2ncia pr\u00e1tica: Mesmo com todas as regras, ainda pode haver incerteza sobre um paciente espec\u00edfico se nem todos os testes necess\u00e1rios foram ou puderam ser executados.</li> </ul> <p>A solu\u00e7\u00e3o para lidar com essa incerteza, nesses casos, \u00e9 a Teoria da Probabilidade. Enquanto um agente l\u00f3gico lida com senten\u00e7as como verdadeiro, falso ou desconhecido, um agente probabil\u00edstico pode ter um grau num\u00e9rico de cren\u00e7a entre 0 (certamente falso) e 1 (certamente verdadeiro). Dessa forma, a teoria da probabilidade fornece uma maneira de resumir a incerteza que vem da falta de tempo e ignor\u00e2ncia, resolvendo o problema da qualifica\u00e7\u00e3o. Por exemplo, podemos acreditar que h\u00e1 80% de chance (probabilidade de 0,8) de um paciente com dor de dente ter c\u00e1rie.</p> <p>Para a tomada de decis\u00e3o sob incerteza, a Teoria da Utilidade pode ser combinada com as probabilidades. A utilidade representa as prefer\u00eancias do agente, onde cada estado (ou sequ\u00eancia de estados) possui um grau de utilidade, e o agente preferir\u00e1 estados com maior utilidade. A Teoria da Decis\u00e3o visa afirmar que um agente \u00e9 racional se escolhe a a\u00e7\u00e3o que produz a maior utilidade esperada (MEU - Maximum Expected Utility), calculada pela m\u00e9dia de todos os poss\u00edveis resultados de uma a\u00e7\u00e3o.</p>"},{"location":"portifolio-5/#notacao-basica-de-probabilidade","title":"Nota\u00e7\u00e3o B\u00e1sica de Probabilidade","text":"<ul> <li>Espa\u00e7o Amostral (Omega) e Mundos Poss\u00edveis (omega): O conjunto de todos os estados de mundos poss\u00edveis \u00e9 -&gt; o espa\u00e7o amostral, e omega representa um elemento dele.</li> <li>Axiomas B\u00e1sicos: Todo estado de mundo poss\u00edvel tem uma probabilidade entre 0 e 1, e a probabilidade do conjunto de todos os estados de mundo poss\u00edveis \u00e9 1.</li> <li>Eventos/Proposi\u00e7\u00f5es: Conjuntos de mundos poss\u00edveis (por exemplo, a probabilidade de dois dados somarem 11). A probabilidade de uma proposi\u00e7\u00e3o \u00e9 a soma das probabilidades dos mundos em que ela \u00e9 v\u00e1lida.</li> <li>Probabilidades Incondicionais (a priori): P(Total = 11) ou P(Duplos).</li> <li>Probabilidades Condicionais (a posteriori): P(a|b) - a probabilidade de 'a' dado 'b'. Definida como P(a E b) / P(b).</li> <li>Regra do Produto: P(a E b) = P(a|b)P(b).</li> <li>Vari\u00e1veis Aleat\u00f3rias: Representadas por letras mai\u00fasculas (e.g., Dado1, Tempo) e seus valores por letras min\u00fasculas (e.g., Dado1 = 5). Podem ser Booleanas (verdadeiro/falso), discretas (Idade = {juvenil, adolescente, adulto}) ou cont\u00ednuas.</li> <li>Distribui\u00e7\u00e3o de Probabilidade: P(X) em negrito indica um vetor de n\u00fameros, definindo a distribui\u00e7\u00e3o para a vari\u00e1vel aleat\u00f3ria. P(X|Y) fornece os valores de P(X=xi | Y=yj).</li> <li>Fun\u00e7\u00e3o Densidade de Probabilidade (PDF): Usada para vari\u00e1veis aleat\u00f3rias cont\u00ednuas.</li> <li>Distribui\u00e7\u00e3o Conjunta de Probabilidade: P(Tempo, C\u00e1rie). Um modelo probabil\u00edstico \u00e9 completamente determinado pela distribui\u00e7\u00e3o de probabilidade conjunta completa de todas as vari\u00e1veis aleat\u00f3rias.</li> <li>Marginaliza\u00e7\u00e3o (Somat\u00f3rio): Para calcular a probabilidade de uma proposi\u00e7\u00e3o, somam-se as probabilidades dos mundos em que ela \u00e9 verdadeira. Este processo remove vari\u00e1veis da equa\u00e7\u00e3o. Ex: P(C\u00e1rie) = P(C\u00e1rie, DorDeDente, Pego) + P(C\u00e1rie, \u00acDorDeDente, Pego) + ....</li> <li>Regra de Condicionamento: P(Y) = Soma_z P(Y|z)P(z).</li> <li>Normaliza\u00e7\u00e3o: Usamos alpha como uma constante para normalizar probabilidades, garantindo que somem 1.</li> </ul>"},{"location":"portifolio-5/#independencia-e-a-regra-de-bayes","title":"Independ\u00eancia e a Regra de Bayes","text":"<ul> <li>Independ\u00eancia: Duas proposi\u00e7\u00f5es 'a' e 'b' s\u00e3o independentes se P(a E b) = P(a)P(b), ou equivalentemente, P(a|b) = P(a). A independ\u00eancia entre vari\u00e1veis pode reduzir dramaticamente a quantidade de informa\u00e7\u00e3o para especificar a distribui\u00e7\u00e3o conjunta completa e a complexidade da infer\u00eancia.</li> <li>Regra de Bayes: Derivada da regra do produto, \u00e9 P(a|b) = P(b|a)P(a) / P(b). Esta equa\u00e7\u00e3o \u00e9 a base da maioria dos sistemas modernos de IA para infer\u00eancia probabil\u00edstica. \u00c9 frequentemente usada quando temos evid\u00eancia do efeito de uma causa desconhecida e desejamos determinar essa causa (P(causa|efeito) a partir de P(efeito|causa)). Por exemplo, um m\u00e9dico sabe P(sintomas|doen\u00e7a) e deseja P(doen\u00e7a|sintomas).<ul> <li>Exemplo da Meningite: Se P(torcicolo|meningite) = 0,7, P(meningite) = 1/50.000, e P(torcicolo) = 0,01. A probabilidade de um paciente com torcicolo ter meningite \u00e9 P(meningite|torcicolo) = (0,7 * 1/50.000) / 0,01 = 0,0014. Isso mostra como uma causa rara (meningite) pode ser inferida mesmo com um sintoma comum (torcicolo).</li> </ul> </li> <li>Combinando Evid\u00eancias: Quando temos m\u00faltiplas evid\u00eancias, como um paciente com dor de dente e uma sonda presa (indicando c\u00e1rie), a complexidade aumenta. A chave \u00e9 a Independ\u00eancia Condicional: Duas vari\u00e1veis X e Y s\u00e3o condicionalmente independentes dada uma terceira vari\u00e1vel Z se P(X, Y|Z) = P(X|Z)P(Y|Z). No exemplo odontol\u00f3gico, a dor de dente e a sonda presa s\u00e3o independentes, dada a presen\u00e7a ou aus\u00eancia de c\u00e1rie. Isso simplifica bastante a modelagem.</li> <li>Modelo de Bayes Ing\u00eanuo: Um padr\u00e3o comum onde uma \u00fanica causa influencia diretamente uma s\u00e9rie de efeitos que s\u00e3o condicionalmente independentes dada a causa. A distribui\u00e7\u00e3o conjunta completa pode ser escrita como P(Causa, Efeitos) = P(Causa) * Produto P(Efeito_i | Causa). Embora seja uma suposi\u00e7\u00e3o simplificadora (\"ing\u00eanua\"), esses sistemas funcionam muito bem na pr\u00e1tica, mesmo quando as condi\u00e7\u00f5es de independ\u00eancia condicional n\u00e3o s\u00e3o estritamente verdadeiras.</li> </ul>"},{"location":"portifolio-5/#redes-bayesianas","title":"Redes Bayesianas","text":"<p>Uma Rede Bayesiana \u00e9 um grafo direcionado ac\u00edclico (DAG) onde cada n\u00f3 corresponde a uma vari\u00e1vel aleat\u00f3ria (discreta ou cont\u00ednua). Liga\u00e7\u00f5es por setas conectam pares de n\u00f3s, onde X \u00e9 um \"genitor\" de Y se h\u00e1 uma seta de X para Y. Cada n\u00f3 X_i tem uma informa\u00e7\u00e3o de probabilidade associada theta(X_i|Parents(X_i)) que quantifica o efeito dos genitores no n\u00f3.</p> <p>A Sem\u00e2ntica das Redes Bayesianas: A rede Bayesiana define cada entrada na distribui\u00e7\u00e3o conjunta P(x_1,...,x_n) como o produto das probabilidades condicionais locais:</p> <p>P(x_1,...,x_n) = Produto P(x_i|parents(x_i))</p> <p>Isso significa que cada par\u00e2metro da rede tem um significado preciso em termos de apenas um pequeno conjunto de vari\u00e1veis, o que \u00e9 crucial para a robustez e facilidade de especifica\u00e7\u00e3o dos modelos. Sendo assim, uma rede Bayesiana pode ser usada para responder a qualquer consulta sobre o dom\u00ednio, somando todos os valores de probabilidade conjunta relevantes.</p> <p>M\u00e9todo para Construir Redes Bayesianas:</p> <ol> <li>N\u00f3s: Determine o conjunto de vari\u00e1veis e ordene-as {X1,...,Xn}. A rede ser\u00e1 mais compacta se as causas precederem os efeitos.</li> <li>Links: Para cada X_i, escolha um conjunto m\u00ednimo de genitores de X1,...,Xi-1 que influenciam diretamente X_i. Adicione um link do genitor para X_i.</li> <li>CPTs: Escreva a tabela de probabilidade condicional, P(X_i|Parents(X_i)).</li> </ol> <p>Este m\u00e9todo, garante que a rede \u00e9 ac\u00edclica e n\u00e3o cont\u00e9m valores de probabilidade redundantes.</p> <p>Independ\u00eancia Condicional em Redes Bayesianas:</p> <ul> <li>Propriedade N\u00e3o-Descendentes: Cada vari\u00e1vel \u00e9 condicionalmente independente de seus n\u00e3o-descendentes, dados seus genitores.</li> <li>Cobertor de Markov: Uma vari\u00e1vel \u00e9 condicionalmente independente de todos os outros n\u00f3s da rede, dados seus genitores, filhos e genitores dos filhos.</li> </ul> <p>Representa\u00e7\u00e3o Eficiente de Distribui\u00e7\u00f5es Condicionais:</p> <ul> <li>N\u00f3s Determin\u00edsticos: \u00c9 0 valor especificado exatamente pelos genitores, sem incerteza.</li> <li>Independ\u00eancia de Contexto Espec\u00edfico (CSI): Uma vari\u00e1vel \u00e9 condicionalmente independente de alguns de seus genitores dados certos valores de outros.</li> <li>OR-Ru\u00eddoso: Permite incerteza sobre a capacidade de cada genitor de causar o filho ser verdadeiro.</li> </ul> <p>Redes Bayesianas com Vari\u00e1veis Cont\u00ednuas:</p> <ul> <li>Discretiza\u00e7\u00e3o: Dividir valores em intervalos fixos.</li> <li>Distribui\u00e7\u00f5es Probabil\u00edsticas: Definir vari\u00e1veis cont\u00ednuas usando fun\u00e7\u00f5es de densidade de probabilidade padr\u00e3o (e.g., Gaussiana).</li> <li>N\u00e3o Param\u00e9trica: Definir a distribui\u00e7\u00e3o condicional implicitamente com uma cole\u00e7\u00e3o de inst\u00e2ncias.</li> </ul> <p>Redes Bayesianas que possuem vari\u00e1veis discretas e cont\u00ednuas s\u00e3o chamadas de Redes Bayesianas H\u00edbridas.</p> <p>Exemplo de Aplica\u00e7\u00e3o:</p> <p>Aqui, ser\u00e1 apresentado uma estrutura conceitual de como uma Rede Bayesiana pode ser implementada em c\u00f3digo, focando na representa\u00e7\u00e3o dos n\u00f3s e na l\u00f3gica de c\u00e1lculo de probabilidade conjunta.</p> Python<pre><code>class Node:\n    def __init__(self, name, parents=None, cpts=None):\n        self.name = name\n        self.parents = parents if parents is not None else []\n        self.cpts = cpts # Conditional Probability Tables (tabelas de probabilidade condicional)\n\nclass BayesianNetwork:\n    def __init__(self):\n        self.nodes = {}\n\n    def add_node(self, node):\n        self.nodes[node.name] = node\n\n    def calculate_joint_probability(self, assignment):\n        # assignment: dicion\u00e1rio de {variable_name: value}\n        # Multiplica as probabilidades condicionais de cada n\u00f3 dado seus pais,\n        # conforme a sem\u00e2ntica da Rede Bayesiana. P(x1,...,xn) = Produto P(xi|parents(xi))\n        joint_prob = 1.0\n        for node_name, node in self.nodes.items():\n            node_value = assignment.get(node_name)\n            if node_value is None:\n                raise ValueError(f\"Missing value for node {node_name} in assignment\")\n\n            parent_values = {p_name: assignment.get(p_name) for p_name in node.parents}\n            conditional_prob = self._get_conditional_probability(node, node_value, parent_values)\n            joint_prob *= conditional_prob\n        return joint_prob\n\n    def _get_conditional_probability(self, node, node_value, parent_values):\n        # L\u00f3gica para obter P(node_value | parent_values) da CPT do n\u00f3.\n        # No fim das contas, CPTs s\u00e3o geralmente representadas como dicion\u00e1rios aninhados ou arrays.\n\n        # Exemplo hipot\u00e9tico para JohnCalls (assumindo uma CPT simplificada):\n        if node.name == \"JohnCalls\":\n            alarm_state = parent_values.get(\"Alarm\")\n            if alarm_state is True:\n                # Se o alarme est\u00e1 ligado, 90% de chance de John ligar (True), 10% de n\u00e3o ligar (False)\n                return node.cpts['true_alarm'].get(node_value, 0.0) \n            elif alarm_state is False:\n                # Se o alarme est\u00e1 desligado, 5% de chance de John ligar (falso positivo), 95% de n\u00e3o ligar\n                return node.cpts['false_alarm'].get(node_value, 0.0) \n\n        # Para n\u00f3s sem pais (raiz), a CPT seria apenas sua probabilidade a priori\n        if not node.parents:\n            return node.cpts.get(node_value, 0.0)\n\n        return 0.0 # Retorna 0.0 se a CPT n\u00e3o for encontrada ou implementada para o n\u00f3\n\n    def inference_by_enumeration(self, query_var, evidence):\n        # C\u00e1lculo de P(query_var | evidence).\n        # Este m\u00e9todo envolve somar sobre todas as combina\u00e7\u00f5es poss\u00edveis de valores das vari\u00e1veis n\u00e3o observadas.\n        # Por exemplo: P(Burglary | JohnCalls=true, MaryCalls=true). As vari\u00e1veis ocultas seriam Earthquake e Alarm.\n        # A complexidade \u00e9 alta para grandes redes, tornando-a computacionalmente cara.\n\n        print(f\"A infer\u00eancia por enumera\u00e7\u00e3o para {query_var} dada {evidence} seria complexa e computacionalmente cara para grandes redes.\")\n        print(\"Envolveria somar sobre todas as combina\u00e7\u00f5es das vari\u00e1veis ocultas (n\u00e3o observadas), multiplicando as probabilidades condicionais locais.\")\n        return \"Conceptual Inference Result (Resultados reais exigem implementa\u00e7\u00e3o completa)\"\n\n# Exemplo de Defini\u00e7\u00e3o da Rede Bayesiana (Problema do Alarme):\n# Nodes: Burglary (B), Earthquake (E), Alarm (A), JohnCalls (J), MaryCalls (M)\n# Links: B -&gt; A, E -&gt; A, A -&gt; J, A -&gt; M\n\n# Definindo as CPTs para o exemplo do alarme (valores hipot\u00e9ticos/ilustrativos para o portf\u00f3lio):\n# Probabilidade a priori de Roubo e Terremoto\ncpt_burglary = {True: 0.001, False: 0.999}\ncpt_earthquake = {True: 0.002, False: 0.998}\n\n# CPT do Alarme dependendo de Roubo e Terremoto\n# P(Alarm | Burglary, Earthquake)\n# Formato: {(Burglary_val, Earthquake_val): {Alarm_True: prob, Alarm_False: prob}}\ncpt_alarm = {\n    (True, True): {True: 0.94, False: 0.06},    # P(A|B,E)\n    (True, False): {True: 0.95, False: 0.05},   # P(A|B,~E)\n    (False, True): {True: 0.29, False: 0.71},   # P(A|~B,E)\n    (False, False): {True: 0.001, False: 0.999} # P(A|~B,~E)\n}\n\n# CPTs para JohnCalls e MaryCalls dependendo do Alarme\n# P(JohnCalls | Alarm)\ncpt_johncalls = {\n    'true_alarm': {True: 0.90, False: 0.10},  # P(J|A)\n    'false_alarm': {True: 0.05, False: 0.95} # P(J|~A) (falso positivo, por exemplo)\n}\n\n# P(MaryCalls | Alarm)\ncpt_marycalls = {\n    'true_alarm': {True: 0.70, False: 0.30},  # P(M|A)\n    'false_alarm': {True: 0.01, False: 0.99} # P(M|~A) (falso positivo, por exemplo)\n}\n\n# Criando os n\u00f3s da rede\nnode_burglary = Node(\"Burglary\", cpts=cpt_burglary)\nnode_earthquake = Node(\"Earthquake\", cpts=cpt_earthquake)\nnode_alarm = Node(\"Alarm\", parents=[\"Burglary\", \"Earthquake\"], cpts=cpt_alarm)\nnode_johncalls = Node(\"JohnCalls\", parents=[\"Alarm\"], cpts=cpt_johncalls)\nnode_marycalls = Node(\"MaryCalls\", parents=[\"Alarm\"], cpts=cpt_marycalls)\n\n# Construindo a rede\nalarm_network = BayesianNetwork()\nalarm_network.add_node(node_burglary)\nalarm_network.add_node(node_earthquake)\nalarm_network.add_node(node_alarm)\nalarm_network.add_node(node_johncalls)\nalarm_network.add_node(node_marycalls)\n\n# Exemplo de uso (conceitual):\n# Suponha que John e Mary ligaram. Qual a probabilidade de ter ocorrido um roubo?\n# assignment_example = {\n#     \"Burglary\": True, \"Earthquake\": False, \"Alarm\": True, \"JohnCalls\": True, \"MaryCalls\": True\n# }\n# joint_prob = alarm_network.calculate_joint_probability(assignment_example)\n# print(f\"\\nProbabilidade conjunta do cen\u00e1rio: {joint_prob:.6f}\")\n\n# Esse \u00e9 um Exemplo de infer\u00eancia (apenas conceitual, pois a implementa\u00e7\u00e3o completa \u00e9 mais complexa)\n# alarm_network.inference_by_enumeration(query_var=\"Burglary\", \n#                                        evidence={\"JohnCalls\": True, \"MaryCalls\": True})\n</code></pre> <p>Para infer\u00eancia em redes bayesianas, especialmente em grandes redes, a infer\u00eancia exata (como por enumera\u00e7\u00e3o) pode ser intrat\u00e1vel. Por exemplo, uma rede como a do seguro de carro precisaria de milh\u00f5es de opera\u00e7\u00f5es aritm\u00e9ticas para uma consulta. M\u00e9todos de infer\u00eancia aproximada, tamb\u00e9m chamados de algoritmos de Monte Carlo, s\u00e3o usados para lidar com isso. Eles s\u00e3o capazes de gerar eventos aleat\u00f3rios com base nas probabilidades da rede Bayesiana e contar as respostas. Com amostras suficientes, podemos nos aproximar da verdadeira distribui\u00e7\u00e3o de probabilidade.</p> <ul> <li>Amostragem Direta: Gera amostras de uma distribui\u00e7\u00e3o de probabilidade conhecida, amostrando cada vari\u00e1vel em ordem topol\u00f3gica.</li> <li>Cadeia de Markov Monte Carlo (MCMC): Gera uma amostra fazendo uma altera\u00e7\u00e3o aleat\u00f3ria na amostra anterior. Exemplos incluem Gibbs Sampling e Metropolis-Hastings.</li> </ul>"},{"location":"portifolio-5/#2-raciocinio-probabilistico-ao-longo-do-tempo","title":"2. Racioc\u00ednio Probabil\u00edstico ao Longo do Tempo","text":"<p>Enquanto problemas est\u00e1ticos tendem a assumir que o estado do mundo n\u00e3o muda significativamente (como em um diagn\u00f3stico de carro), problemas din\u00e2micos envolvem estados que mudam com o tempo (como monitorar um paciente com diabetes ou rastrear a posi\u00e7\u00e3o de um ve\u00edculo). Para modelar isso, consideramos problemas de tempo discreto, onde as amostras temporais s\u00e3o enumeradas (0, 1, 2, ...).</p> <ul> <li>Vari\u00e1veis de Estado (Xt): Vari\u00e1veis n\u00e3o observ\u00e1veis no tempo t (ex: a verdadeira posi\u00e7\u00e3o de um carro).</li> <li>Vari\u00e1veis de Evid\u00eancia (Et): Vari\u00e1veis observ\u00e1veis no tempo t (ex: leituras do GPS do carro).</li> </ul> <p>Dois componentes-chave s\u00e3o necess\u00e1rios:</p> <ul> <li>Modelo de Transi\u00e7\u00e3o: Especifica como o mundo evolui, ou seja, a distribui\u00e7\u00e3o de probabilidade das vari\u00e1veis de estado mais recentes, dados os valores anteriores, P(Xt|X0:t-1). Para resolver o problema de o hist\u00f3rico crescer infinitamente, fazemos uma suposi\u00e7\u00e3o de Markov: o estado atual depende apenas de um n\u00famero fixo finito de estados anteriores. A forma mais simples \u00e9 um processo de Markov de 1\u00aa ordem, onde P(Xt|Xt-1).</li> <li>Modelo de Sensor (ou Observa\u00e7\u00e3o): Especifica como as vari\u00e1veis de evid\u00eancia recebem seus valores, P(Et|X0:t, E1:t-1). A suposi\u00e7\u00e3o de sensor de Markov simplifica isso para P(Et|Xt).</li> </ul> <p>Al\u00e9m desses modelos, precisamos da distribui\u00e7\u00e3o de probabilidade a priori no tempo 0, P(X0). Com isso, a distribui\u00e7\u00e3o conjunta completa sobre todas as vari\u00e1veis \u00e9 dada por:</p> <p>P(X0:t, E1:t) = P(X0) * Produto [P(Xi|Xi-1) * P(Ei|Xi)]</p> <p>Temos ent\u00e3o como um exemplo cl\u00e1ssico o \"Mundo do Guarda-Chuva\", que \u00e9 um processo de Markov de primeira ordem onde a probabilidade de chuva depende da chuva no dia anterior, e a observa\u00e7\u00e3o (guarda-chuva) depende do estado da chuva.</p>"},{"location":"portifolio-5/#inferencia-em-modelos-temporais","title":"Infer\u00eancia em Modelos Temporais","text":"<p>Quatro tarefas b\u00e1sicas de infer\u00eancia s\u00e3o importantes:</p> <ul> <li>Filtragem (ou Estima\u00e7\u00e3o de Estados): Calcular a distribui\u00e7\u00e3o a posteriori do estado mais recente, dado todas as evid\u00eancias at\u00e9 o momento: P(Xt|e1:t). Um algoritmo de filtragem \u00fatil mant\u00e9m o estado atual e o atualiza, em vez de voltar a todo o hist\u00f3rico de percep\u00e7\u00f5es. O c\u00e1lculo envolve projetar a distribui\u00e7\u00e3o de estados de t para t+1 e depois atualiz\u00e1-la com a nova evid\u00eancia.<ul> <li>Equa\u00e7\u00e3o Recursiva para Filtragem: P(Xt+1|e1:t+1) = alpha P(et+1|Xt+1) Soma P(Xt+1|Xt) P(Xt|e1:t). (Conhecida como \"Forward Message\")</li> </ul> </li> <li>Predi\u00e7\u00e3o: Calcular a distribui\u00e7\u00e3o a posteriori de um estado futuro, dada todas as evid\u00eancias at\u00e9 o instante de tempo atual: P(Xt+k |e1:t) para k &gt; 0.</li> <li>Suaviza\u00e7\u00e3o (Smoothing): Computar a distribui\u00e7\u00e3o a posteriori de um estado passado, dada todas as evid\u00eancias at\u00e9 o instante de tempo atual: P(Xk|e1:t) para 0 \\&lt;= k \\&lt; t. Isso pode ser feito recursivamente, dividindo a evid\u00eancia em duas partes. (Conhecida como \"Backward Message\")</li> <li>Explica\u00e7\u00e3o Mais Prov\u00e1vel: Dada uma sequ\u00eancia de observa\u00e7\u00f5es, encontrar a sequ\u00eancia de estados que mais provavelmente gerou essas observa\u00e7\u00f5es: argmax x1:t P(x1:t |e1:t). Isso \u00e9 resolvido pelo Algoritmo de Viterbi, que encontra o caminho mais prov\u00e1vel atrav\u00e9s dos estados ao longo do tempo.</li> </ul>"},{"location":"portifolio-5/#modelo-oculto-de-markov-hmm","title":"Modelo Oculto de Markov (HMM)","text":"<p>Um HMM \u00e9 um modelo probabil\u00edstico temporal onde o estado do processo \u00e9 descrito por uma \u00fanica vari\u00e1vel aleat\u00f3ria discreta. O \"Mundo do Guarda-Chuva\" \u00e9 um exemplo de HMM, pois possui uma \u00fanica vari\u00e1vel de estado (\"chuva\"). Embora os HMMs exijam um estado discreto, n\u00e3o h\u00e1 restri\u00e7\u00e3o para as vari\u00e1veis de evid\u00eancia, pois elas s\u00e3o sempre observadas.</p> <p>Algoritmos Matriciais Simplificados para HMMs:</p> <p>Para uma \u00fanica vari\u00e1vel de estado discreta Xt com 'S' valores poss\u00edveis:</p> <ul> <li>O modelo de transi\u00e7\u00e3o P(Xt|Xt-1) torna-se uma matriz S x S T, onde T_i,j \u00e9 a probabilidade de transi\u00e7\u00e3o do estado i para o estado j.</li> <li>O modelo de sensor P(Et|Xt) torna-se uma matriz de observa\u00e7\u00e3o S x S Ot para cada passo de tempo. A i-\u00e9sima entrada diagonal de Ot \u00e9 P(et|Xt=i) e as outras entradas s\u00e3o 0.</li> </ul> <p>As equa\u00e7\u00f5es recursivas de filtragem e suaviza\u00e7\u00e3o podem ser expressas de forma concisa usando essas matrizes.</p> <p>Exemplo de Aplica\u00e7\u00e3o:</p> <p>O exemplo abaixo demonstra a estrutura de um HMM para o \"Mundo do Guarda-Chuva\", representando suas probabilidades de transi\u00e7\u00e3o e observa\u00e7\u00e3o como matrizes e dicion\u00e1rios.</p> Python<pre><code># Conceito de Estrutura de C\u00f3digo para Modelos Ocultos de Markov (HMM)\nimport numpy as np\n\nclass HMM:\n    def __init__(self, states, observations_map, transition_matrix, initial_state_prob):\n        self.states = states \n        self.observations_map = observations_map # Mapeia evid\u00eancias para distribui\u00e7\u00f5es de probabilidade P(E|X)\n        self.T = np.array(transition_matrix) \n        self.pi = np.array(initial_state_prob) \n\n    def _create_observation_matrix(self, observed_evidence):\n        # Ot \u00e9 uma matriz diagonal onde O_t[i,i] = P(observed_evidence | Xt=states[i])\n        S = len(self.states)\n        O_t = np.diag([self.observations_map[state][observed_evidence] for state in self.states])\n        return O_t\n\n    def forward_algorithm(self, evidences_sequence):\n        # Implementa o algoritmo de filtragem (forward algorithm)\n        # alpha_t = alpha * Ot * T.T * alpha_t-1\n\n        alpha = self.pi \n        filtered_states = []\n\n        for evidence in evidences_sequence:\n            O_t = self._create_observation_matrix(evidence)\n\n            # Etapa de Predi\u00e7\u00e3o: projected_alpha = T.T @ alpha (P(Xt+1|e1:t) n\u00e3o normalizado)\n            predicted_alpha = np.dot(self.T.T, alpha)\n\n            # Etapa de Atualiza\u00e7\u00e3o: alpha = O_t @ predicted_alpha (P(Xt+1|e1:t+1) n\u00e3o normalizado)\n            updated_alpha_unnormalized = np.dot(O_t, predicted_alpha)\n\n            # Normaliza\u00e7\u00e3o\n            alpha = updated_alpha_unnormalized / np.sum(updated_alpha_unnormalized)\n            filtered_states.append(alpha)\n\n        return filtered_states\n\n    def backward_algorithm(self, evidences_sequence):\n        # Implementa o algoritmo de suaviza\u00e7\u00e3o (backward algorithm)\n        # b_k:t = T * O_k+1 * b_k+1:t\n\n        S = len(self.states)\n        b = np.ones(S) # Inicializa\u00e7\u00e3o P(e_t+1:t | Xt) = 1 (para o \u00faltimo passo)\n\n        backward_messages = [b]\n        # Itera de tr\u00e1s para frente na sequ\u00eancia de evid\u00eancias (excluindo a \u00faltima)\n        for t in range(len(evidences_sequence) - 1, 0, -1):\n            O_t_plus_1 = self._create_observation_matrix(evidences_sequence[t])\n            # Calcula b_k (P(e_k+1:t | X_k))\n            b = np.dot(self.T, np.dot(O_t_plus_1, b))\n            backward_messages.insert(0, b)\n\n        return backward_messages\n\n    def smooth_states(self, evidences_sequence):\n        # Combina forward e backward para suaviza\u00e7\u00e3o\n        # P(Xk|e1:t) = alpha * f_1:k * b_k+1:t (elemento a elemento)\n        filtered_messages = [self.pi] + self.forward_algorithm(evidences_sequence) # Inclui P(X0) no in\u00edcio\n        backward_messages = self.backward_algorithm(evidences_sequence)\n\n        smoothed_states = []\n        for k in range(len(evidences_sequence)): # Itera sobre t=0 at\u00e9 T-1 (para evidences_sequence)\n            smoothed_unnormalized = filtered_messages[k] * backward_messages[k]\n            smoothed_states.append(smoothed_unnormalized / np.sum(smoothed_unnormalized))\n        return smoothed_states\n\n    def viterbi_algorithm(self, evidences_sequence):\n        # Implementa o algoritmo de Viterbi para encontrar a sequ\u00eancia de estados mais prov\u00e1vel\n        # m_1:t+1(x_t+1) = P(e_t+1|x_t+1) * max_{x_t} (P(x_t+1|x_t) * m_1:t(x_t))\n\n        S = len(self.states)\n        T_steps = len(evidences_sequence)\n\n        dp_table = np.zeros((S, T_steps)) # Armazena a probabilidade do caminho mais prov\u00e1vel at\u00e9 o estado t\n        path_table = np.zeros((S, T_steps), dtype=int) # Armazena os backpointers para reconstruir o caminho\n\n        # Inicializa\u00e7\u00e3o (t=0)\n        O0 = self._create_observation_matrix(evidences_sequence[0])\n        dp_table[:, 0] = self.pi * np.diag(O0)\n\n        # Itera\u00e7\u00e3o para t=1 at\u00e9 T_steps-1\n        for t in range(1, T_steps):\n            O_t = self._create_observation_matrix(evidences_sequence[t])\n            for j in range(S): # Para cada estado atual j\n                possible_prev_probs = np.array([dp_table[i, t-1] * self.T[i, j] for i in range(S)])\n\n                max_prob = np.max(possible_prev_probs)\n                max_idx = np.argmax(possible_prev_probs)\n\n                dp_table[j, t] = np.diag(O_t)[j] * max_prob\n                path_table[j, t] = max_idx\n\n        # Reconstru\u00e7\u00e3o do caminho mais prov\u00e1vel\n        most_likely_path = [np.argmax(dp_table[:, T_steps-1])]\n        for t in range(T_steps-1, 0, -1):\n            most_likely_path.insert(0, path_table[most_likely_path[0], t])\n\n        return [self.states[idx] for idx in most_likely_path]\n\n# Exemplo de uso conceitual para o Mundo do Guarda-Chuva:\n# Estados: 'Rain', 'NoRain'\n# Observa\u00e7\u00f5es: 'Umbrella', 'NoUmbrella'\n\n# Probabilidades de Transi\u00e7\u00e3o (T): P(Xt|Xt-1)\n# T[i,j] = P(State_j | State_i)\n# Ex: T = [[P(Rain|Rain), P(NoRain|Rain)], [P(Rain|NoRain), P(NoRain|NoRain)]]\ntransition_matrix_ex = [[0.7, 0.3], # Se estava chovendo, 70% de chance de chover no pr\u00f3ximo dia\n                        [0.3, 0.7]] # Se n\u00e3o estava chovendo, 30% de chance de chover no pr\u00f3ximo dia\n\n# Probabilidades Iniciais (pi): P(X0)\n# Ex: pi = [P(Rain), P(NoRain)]\ninitial_state_prob_ex = [0.5, 0.5] # 50% de chance de chover no dia 0\n\n# Probabilidades de Observa\u00e7\u00e3o (observations_map): P(E|X)\nobservations_map_ex = {\n    'Rain': {'Umbrella': 0.9, 'NoUmbrella': 0.1}, # Se est\u00e1 chovendo, 90% de chance de levar guarda-chuva\n    'NoRain': {'Umbrella': 0.2, 'NoUmbrella': 0.8} # Se n\u00e3o est\u00e1 chovendo, 20% de chance de levar guarda-chuva (por precau\u00e7\u00e3o)\n}\n\nhmm_model = HMM(\n    states=['Rain', 'NoRain'],\n    observations_map=observations_map_ex,\n    transition_matrix=transition_matrix_ex,\n    initial_state_prob=initial_state_prob_ex\n)\n\n# Exemplo de sequ\u00eancia de evid\u00eancias (observa\u00e7\u00f5es de guarda-chuva ao longo de 3 dias)\nevidences = ['Umbrella', 'Umbrella', 'NoUmbrella']\n</code></pre>"},{"location":"portifolio-5/#3-filtros-de-kalman","title":"3. Filtros de Kalman","text":"<p>At\u00e9 o momento, foi abordado os modelos onde as vari\u00e1veis de estado eram discretas. Mas e se o estado do mundo \u00e9 cont\u00ednuo, como a posi\u00e7\u00e3o e velocidade de um carro, ou a temperatura de uma sala? Para esses cen\u00e1rios, os Filtros de Kalman s\u00e3o uma ferramenta poderosa para a estima\u00e7\u00e3o \u00f3tima de estados em sistemas din\u00e2micos lineares com ru\u00eddo Gaussiano.</p> <p>Um Filtro de Kalman \u00e9 um algoritmo recursivo que permite estimar o estado de um processo com base em uma s\u00e9rie de medi\u00e7\u00f5es ruidosas. Ele \u00e9 amplamente utilizado em navega\u00e7\u00e3o, controle de rob\u00f4s, sistemas de rastreamento e muitas outras aplica\u00e7\u00f5es de engenharia e IA.</p> <p>A intui\u00e7\u00e3o por tr\u00e1s do Filtro de Kalman \u00e9 que ele combina duas fontes de informa\u00e7\u00e3o:</p> <ol> <li>Modelo de Previs\u00e3o (Modelo de Transi\u00e7\u00e3o de Estado): Como o estado do sistema se espera que evolua ao longo do tempo. Este modelo \u00e9 baseado nas leis da f\u00edsica ou em um entendimento do comportamento do sistema, e tamb\u00e9m inclui o ru\u00eddo do processo (incerteza em como o sistema se move).</li> <li>Modelo de Medi\u00e7\u00e3o (Modelo de Sensor): Como as medi\u00e7\u00f5es observadas se relacionam com o estado verdadeiro do sistema. Este modelo tamb\u00e9m considera o ru\u00eddo da medi\u00e7\u00e3o (incerteza nas leituras do sensor).</li> </ol> <p>O filtro opera em duas fases principais de forma recursiva:</p> <ul> <li>Fase de Predi\u00e7\u00e3o: O filtro estima o estado atual e a incerteza associada com base na estimativa do estado anterior e no modelo de transi\u00e7\u00e3o do sistema. Isso gera uma \"previs\u00e3o a priori\" ou \"predi\u00e7\u00e3o\".</li> <li>Fase de Atualiza\u00e7\u00e3o: Quando uma nova medi\u00e7\u00e3o se torna dispon\u00edvel, o filtro combina essa medi\u00e7\u00e3o com a previs\u00e3o a priori para refinar a estimativa do estado. A medi\u00e7\u00e3o ruidosa \u00e9 ponderada pela sua incerteza e pela incerteza da previs\u00e3o, resultando em uma \"estimativa a posteriori\" ou \"corre\u00e7\u00e3o\".</li> </ul> <p>A beleza do Filtro de Kalman reside em sua capacidade de fornecer uma estimativa \u00f3tima (no sentido de minimizar o erro quadr\u00e1tico m\u00e9dio) para sistemas lineares Gaussianos, mesmo quando as medi\u00e7\u00f5es s\u00e3o imprecisas e o sistema \u00e9 afetado por ru\u00eddo. A incerteza do estado \u00e9 representada por uma matriz de covari\u00e2ncia, que \u00e9 atualizada em cada passo do tempo, refletindo como a confian\u00e7a na estimativa do estado muda.</p>"},{"location":"portifolio-5/#equacoes-do-filtro-de-kalman","title":"Equa\u00e7\u00f5es do Filtro de Kalman","text":"<p>Vamos representar o estado do sistema no tempo <code>t</code> como um vetor <code>x_t</code> e a medi\u00e7\u00e3o como um vetor <code>z_t</code>.</p> <p>Fase de Predi\u00e7\u00e3o:</p> <ol> <li>Estado Previsto (a priori): <code>x\u0302_t|t-1 = F_t * x\u0302_t-1|t-1 + B_t * u_t</code><ul> <li><code>x\u0302_t|t-1</code>: Estimativa do estado no tempo <code>t</code> baseada nas informa\u00e7\u00f5es at\u00e9 <code>t-1</code>.</li> <li><code>F_t</code>: Matriz de transi\u00e7\u00e3o de estado.</li> <li><code>x\u0302_t-1|t-1</code>: Estimativa do estado anterior (corrigida).</li> <li><code>B_t</code>: Matriz de controle (opcional, para entradas de controle <code>u_t</code>).</li> <li><code>u_t</code>: Vetor de controle.</li> </ul> </li> <li>Covari\u00e2ncia Prevista (a priori): <code>P_t|t-1 = F_t * P_t-1|t-1 * F_t.T + Q_t</code><ul> <li><code>P_t|t-1</code>: Matriz de covari\u00e2ncia do erro da previs\u00e3o.</li> <li><code>P_t-1|t-1</code>: Matriz de covari\u00e2ncia do erro da estimativa anterior (corrigida).</li> <li><code>Q_t</code>: Matriz de covari\u00e2ncia do ru\u00eddo do processo (reflete incertezas no modelo).</li> </ul> </li> </ol> <p>Fase de Atualiza\u00e7\u00e3o:</p> <ol> <li>Ganho de Kalman: <code>K_t = P_t|t-1 * H_t.T * (H_t * P_t|t-1 * H_t.T + R_t)^-1</code><ul> <li><code>K_t</code>: Ganho de Kalman, pondera o quanto a medi\u00e7\u00e3o influencia a corre\u00e7\u00e3o da estimativa.</li> <li><code>H_t</code>: Matriz de observa\u00e7\u00e3o (transforma o estado em espa\u00e7o de medi\u00e7\u00e3o).</li> <li><code>R_t</code>: Matriz de covari\u00e2ncia do ru\u00eddo da medi\u00e7\u00e3o (reflete incertezas do sensor).</li> </ul> </li> <li>Estado Corrigido (a posteriori): <code>x\u0302_t|t = x\u0302_t|t-1 + K_t * (z_t - H_t * x\u0302_t|t-1)</code><ul> <li><code>x\u0302_t|t</code>: Estimativa final do estado no tempo <code>t</code> ap\u00f3s incorporar a medi\u00e7\u00e3o.</li> <li><code>z_t</code>: Vetor de medi\u00e7\u00f5es no tempo <code>t</code>.</li> </ul> </li> <li>Covari\u00e2ncia Corrigida (a posteriori): <code>P_t|t = (I - K_t * H_t) * P_t|t-1</code><ul> <li><code>P_t|t</code>: Matriz de covari\u00e2ncia do erro da estimativa corrigida.</li> <li><code>I</code>: Matriz identidade.</li> </ul> </li> </ol>"},{"location":"portifolio-5/#exemplo-de-aplicacao","title":"Exemplo de Aplica\u00e7\u00e3o","text":"<p>Considere o rastreamento de um objeto se movendo em uma dimens\u00e3o (por exemplo, um carro em uma estrada reta). O estado <code>x</code> pode ser definido como <code>[posi\u00e7\u00e3o, velocidade]</code>.</p> Python<pre><code># Conceito de Estrutura de C\u00f3digo para Filtro de Kalman\nimport numpy as np\n\nclass KalmanFilter:\n    def __init__(self, initial_state, initial_covariance, F, H, Q, R, B=None):\n        self.x_hat = initial_state         \n        self.P = initial_covariance        # P_t-1|t-1 (Covari\u00e2ncia inicial do erro)\n        self.F = F                         \n        self.H = H                         \n        self.Q = Q                         \n        self.R = R                         \n        self.B = B                         \n\n    def predict(self, u=None):\n        # 1. Estado Previsto: x\u0302_t|t-1 = F_t * x\u0302_t-1|t-1 + B_t * u_t\n        if self.B is not None and u is not None:\n            self.x_hat_prior = np.dot(self.F, self.x_hat) + np.dot(self.B, u)\n        else:\n            self.x_hat_prior = np.dot(self.F, self.x_hat)\n\n        # 2. Covari\u00e2ncia Prevista: P_t|t-1 = F_t * P_t-1|t-1 * F_t.T + Q_t\n        self.P_prior = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n\n        return self.x_hat_prior, self.P_prior\n\n    def update(self, z):\n        # 3. Ganho de Kalman: K_t = P_t|t-1 * H_t.T * (H_t * P_t|t-1 * H_t.T + R_t)^-1\n        # Inova\u00e7\u00e3o ou Res\u00edduo: y = z_t - H_t * x\u0302_t|t-1\n        y = z - np.dot(self.H, self.x_hat_prior)\n\n        # Covari\u00e2ncia da Inova\u00e7\u00e3o: S = H_t * P_t|t-1 * H_t.T + R_t\n        S = np.dot(np.dot(self.H, self.P_prior), self.H.T) + self.R\n\n        K = np.dot(np.dot(self.P_prior, self.H.T), np.linalg.inv(S))\n\n        # 4. Estado Corrigido: x\u0302_t|t = x\u0302_t|t-1 + K_t * (z_t - H_t * x\u0302_t|t-1)\n        self.x_hat = self.x_hat_prior + np.dot(K, y)\n\n        # 5. Covari\u00e2ncia Corrigida: P_t|t = (I - K_t * H_t) * P_t|t-1\n        I = np.eye(self.P.shape[0])\n        self.P = np.dot((I - np.dot(K, self.H)), self.P_prior)\n\n        return self.x_hat, self.P\n\n# --- Exemplo de Uso de um Filtro de Kalman para Rastreamento de Posi\u00e7\u00e3o/Velocidade ---\n\n# Definindo o intervalo de tempo (dt) e o ru\u00eddo\ndt = 1.0 # Segundo\nprocess_noise_std = 0.1 # Desvio padr\u00e3o do ru\u00eddo do processo\nmeasurement_noise_std = 0.5 # Desvio padr\u00e3o do ru\u00eddo da medi\u00e7\u00e3o\n\n# Estado inicial: [posi\u00e7\u00e3o, velocidade]\ninitial_state = np.array([0.0, 0.0]) # Posi\u00e7\u00e3o 0, velocidade 0\n# Covari\u00e2ncia inicial: Muita incerteza no in\u00edcio\ninitial_covariance = np.array([[1.0, 0.0],\n                               [0.0, 1.0]])\n\n# Matriz de Transi\u00e7\u00e3o de Estado (F):\n# Nova posi\u00e7\u00e3o = Posi\u00e7\u00e3o anterior + Velocidade * dt\nF_matrix = np.array([[1.0, dt],\n                     [0.0, 1.0]])\n\n# Matriz de Observa\u00e7\u00e3o (H):\nH_matrix = np.array([[1.0, 0.0]])\n\n# Matriz de Covari\u00e2ncia do Ru\u00eddo do Processo (Q):\nQ_matrix = np.array([[0.25 * dt**4, 0.5 * dt**3],\n                     [0.5 * dt**3, dt**2]]) * process_noise_std**2\n\n# Matriz de Covari\u00e2ncia do Ru\u00eddo da Medi\u00e7\u00e3o (R):\n# Reflete a incerteza das leituras do sensor (GPS ruidoso).\nR_matrix = np.array([[measurement_noise_std**2]])\n\n# Criando o filtro de Kalman\nkf = KalmanFilter(initial_state, initial_covariance, F_matrix, H_matrix, Q_matrix, R_matrix)\n\ntrue_positions = []\nmeasured_positions = []\nestimated_positions = []\n\ntrue_pos = 0.0\ntrue_vel = 1.0 # Velocidade constante de 1 m/s\n\nnum_steps = 20\nfor i in range(num_steps):\n    # Simula o estado real (com algum ru\u00eddo de processo real)\n    process_noise = np.random.normal(0, process_noise_std, 2) # [ru\u00eddo_pos, ru\u00eddo_vel]\n    true_pos = true_pos + true_vel * dt + process_noise[0]\n    true_vel = true_vel + process_noise[1] # Velocidade pode variar ligeiramente\n\n    true_state = np.array([true_pos, true_vel])\n    true_positions.append(true_state[0])\n\n    # Simula a medi\u00e7\u00e3o ruidosa (apenas posi\u00e7\u00e3o)\n    measurement_noise = np.random.normal(0, measurement_noise_std)\n    measured_pos = true_pos + measurement_noise\n    measured_positions.append(measured_pos)\n\n    # Aplica o Filtro de Kalman\n    kf.predict()\n    estimated_state, _ = kf.update(np.array([measured_pos]))\n    estimated_positions.append(estimated_state[0])\n\nprint(\"\\n--- Exemplo de Rastreamento com Filtro de Kalman ---\")\nprint(f\"N\u00famero de passos simulados: {num_steps}\")\nprint(f\"Primeiras 5 Posi\u00e7\u00f5es Reais: {true_positions[:5]}\")\nprint(f\"Primeiras 5 Posi\u00e7\u00f5es Medidas: {measured_positions[:5]}\")\nprint(f\"Primeiras 5 Posi\u00e7\u00f5es Estimadas: {estimated_positions[:5]}\")\nprint(\"\\n(Em um portf\u00f3lio real, gr\u00e1ficos mostrando a redu\u00e7\u00e3o do ru\u00eddo seriam ideais)\")\n</code></pre>"},{"location":"portifolio-5/#referencias","title":"Refer\u00eancias","text":"<ul> <li>RUSSELL, Stuart J.; NORVIG, Peter. Intelig\u00eancia Artificial. 3. ed. Rio de Janeiro: Elsevier, 2013. (T\u00edtulo original: Artificial Intelligence: A Modern Approach)</li> <li>LUGER, George F. Intelig\u00eancia Artificial: estruturas e estrat\u00e9gias para a resolu\u00e7\u00e3o de problemas complexos. 6. ed. Pearson, 2009.</li> <li>NILSSON, Nils J. Artificial Intelligence: A New Synthesis. Morgan Kaufmann, 1998.</li> <li>THRUN, Sebastian; BURGARD, Wolfram; FOX, Dieter. Probabilistic Robotics. MIT Press, 2005.</li> <li>DEAN, Thomas L.; KANAZAWA, Keiji. A Model for Reasoning About Persistence and Causation. Computational Intelligence, v. 5, n. 3, p. 142-150, 1989.</li> </ul>"},{"location":"portifolio-6/","title":"Portifolio 6","text":""}]}